# -*- coding: utf-8 -*-
"""
    LLMæœåŠ¡ - æ™ºèƒ½æ¨é€ç”Ÿæˆ
    :copyright: (c) 2025 by Mood Bakery Team.
    :license: Apache 2.0, see LICENSE for more details.
"""
import os
import json
import requests
from flask import current_app
from .sentiment_lexicon import SentimentLexicon


class LLMService:
    """LLMæœåŠ¡ç±»"""
    
    # æƒ…ç»ªä»»åŠ¡æ¨¡æ¿ï¼ˆå‚è€ƒcntextçš„è®¾è®¡ï¼‰
    EMOTION_TASK_TEMPLATES = {
        'emotion_simple': {
            'prompt': 'åˆ†ææ–‡æœ¬çš„æƒ…ç»ªçŠ¶æ€ï¼Œè¿”å›æƒ…ç»ªæ ‡ç­¾åç§°ï¼ˆå¦‚ï¼šå¼€å¿ƒã€éš¾è¿‡ã€ç„¦è™‘ç­‰ï¼‰ã€‚',
            'output_format': {'label': str}
        },
        'emotion_enhanced': {
            'prompt': 'åˆ†ææ–‡æœ¬çš„æƒ…ç»ªçŠ¶æ€ï¼Œè¿”å›æƒ…ç»ªæ ‡ç­¾ã€åˆ†å€¼ã€ç½®ä¿¡åº¦å’Œå¼ºåº¦ã€‚',
            'output_format': {
                'label': str,
                'score': float,      # -1.0 ~ 1.0ï¼Œè´Ÿæ•°ä¸ºè´Ÿé¢ï¼Œæ­£æ•°ä¸ºæ­£é¢
                'confidence': float, # 0.0 ~ 1.0ï¼Œç½®ä¿¡åº¦
                'intensity': float   # 0.0 ~ 1.0ï¼Œå¼ºåº¦
            }
        },
        'emotion_multi_dimension': {
            'prompt': 'ä»å¤šä¸ªç»´åº¦åˆ†ææ–‡æœ¬æƒ…ç»ªï¼šä¸»è¦æƒ…ç»ªã€æ¬¡è¦æƒ…ç»ªã€æƒ…ç»ªå€¾å‘ã€å¼ºåº¦ã€ç½®ä¿¡åº¦ã€‚',
            'output_format': {
                'primary_emotion': str,
                'secondary_emotion': str,
                'valence': str,      # 'positive'/'negative'/'neutral'
                'intensity': float,
                'confidence': float
            }
        }
    }
    
    # æç¤ºè¯æ¨¡æ¿
    PROMPT_TEMPLATE = """ä½ æ˜¯ä¸€ä½æ¸©æš–çš„å¿ƒç†é™ªä¼´è€…ï¼Œè¯·æ ¹æ®ç”¨æˆ·çš„æƒ…ç»ªå’Œå†…å®¹ï¼Œç”Ÿæˆä¸€å¥æ¸©æš–ã€æ²»æ„ˆçš„è¯ã€‚

ç”¨æˆ·æƒ…ç»ªï¼š{emotion}
ç”¨æˆ·å†…å®¹ï¼š{content}

è¦æ±‚ï¼š
1. è¯­è¨€æ¸©æš–ã€çœŸè¯šã€ä¸è¯´æ•™
2. 50å­—ä»¥å†…
3. è´´åˆç”¨æˆ·çš„æƒ…ç»ªçŠ¶æ€
4. ç»™äºˆé¼“åŠ±å’Œæ”¯æŒ
5. å¯ä»¥ä½¿ç”¨emojiè¡¨æƒ…

è¯·åªè¿”å›ä¸€å¥è¯ï¼Œä¸è¦æœ‰å…¶ä»–å†…å®¹ï¼š"""

    # é¢„è®¾æ¸©æš–å¥å­ï¼ˆé™çº§æ–¹æ¡ˆï¼‰
    FALLBACK_MESSAGES = {
        'å¼€å¿ƒ': [
            "æ„¿ä½ çš„ç¬‘å®¹æ°¸è¿œç¿çƒ‚å¦‚é˜³å…‰ â˜€ï¸",
            "å¿«ä¹çš„æ—¶å…‰å€¼å¾—è¢«è®°å½•ï¼Œç»§ç»­ä¿æŒè¿™ä»½ç¾å¥½å§ âœ¨",
            "çœ‹åˆ°ä½ å¼€å¿ƒï¼Œæˆ‘ä¹Ÿè·Ÿç€å¼€å¿ƒèµ·æ¥äº† ğŸ˜Š"
        ],
        'éš¾è¿‡': [
            "éš¾è¿‡çš„æ—¶å€™ï¼Œç»™è‡ªå·±ä¸€ä¸ªæ¸©æš–çš„æ‹¥æŠ± ğŸ¤—",
            "æ¯ä¸€æ¬¡éš¾è¿‡éƒ½ä¼šè¿‡å»ï¼Œè€Œä½ ä¼šå˜å¾—æ›´å¼ºå¤§ ğŸ’ª",
            "å…è®¸è‡ªå·±éš¾è¿‡ï¼Œè¿™ä¹Ÿæ˜¯çˆ±è‡ªå·±çš„ä¸€ç§æ–¹å¼ ğŸ’™"
        ],
        'ç„¦è™‘': [
            "æ·±å‘¼å¸ï¼Œä¸€åˆ‡éƒ½ä¼šå¥½èµ·æ¥çš„ ğŸŒˆ",
            "ç„¦è™‘åªæ˜¯æš‚æ—¶çš„ï¼Œä½ æœ‰èƒ½åŠ›é¢å¯¹ä¸€åˆ‡ ğŸŒŸ",
            "ç»™è‡ªå·±ä¸€äº›æ—¶é—´ï¼Œæ…¢æ…¢æ¥ï¼Œä¸ç€æ€¥ ğŸ•Šï¸"
        ],
        'å¹³é™': [
            "å¹³é™æ˜¯ä¸€ç§éš¾å¾—çš„å¹¸ç¦ï¼Œå¥½å¥½äº«å—è¿™ä»½å®é™ ğŸƒ",
            "åœ¨å¹³é™ä¸­ï¼Œæˆ‘ä»¬èƒ½å¬è§å†…å¿ƒçš„å£°éŸ³ ğŸµ",
            "å¹³é™çš„å¿ƒï¼Œæ˜¯æœ€å¥½çš„ç¤¼ç‰© ğŸ"
        ],
        'ç–²æƒ«': [
            "ç´¯äº†å°±ä¼‘æ¯ï¼Œä½ å·²ç»å¾ˆåŠªåŠ›äº† ğŸ˜´",
            "ç»™è‡ªå·±æ”¾ä¸ªå‡ï¼Œå¥½å¥½ä¼‘æ¯ä¸€ä¸‹å§ ğŸ›Œ",
            "ç–²æƒ«æ˜¯èº«ä½“åœ¨æé†’ä½ ï¼šè¯¥å¥½å¥½çˆ±è‡ªå·±äº† ğŸ’•"
        ],
        'default': [
            "æ— è®ºæ­¤åˆ»å¦‚ä½•ï¼Œä½ éƒ½å€¼å¾—è¢«æ¸©æŸ”ä»¥å¾… ğŸŒ¸",
            "æ¯ä¸€å¤©éƒ½æ˜¯æ–°çš„å¼€å§‹ï¼ŒåŠ æ²¹ ğŸ’ª",
            "ä½ æ¯”è‡ªå·±æƒ³è±¡çš„æ›´å‹‡æ•¢ã€æ›´å¼ºå¤§ â­"
        ]
    }

    @classmethod
    def generate_soul_message(cls, emotion_name, content, user_context=None):
        """
        ç”Ÿæˆå¿ƒçµé¸¡æ±¤
        
        Args:
            emotion_name: æƒ…ç»ªæ ‡ç­¾åç§°
            content: ç”¨æˆ·å†…å®¹ï¼ˆæ—¥è®°æˆ–å¸–å­ï¼‰
            user_context: ç”¨æˆ·ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼ˆå¯é€‰ï¼‰
        
        Returns:
            dict: {
                'content': 'ç”Ÿæˆçš„å¥å­',
                'model': 'ä½¿ç”¨çš„æ¨¡å‹',
                'success': True/False
            }
        """
        # å°è¯•ä½¿ç”¨LLMç”Ÿæˆ
        try:
            result = cls._call_llm_api(emotion_name, content)
            if result['success']:
                return result
        except Exception as e:
            current_app.logger.error(f"LLMè°ƒç”¨å¤±è´¥: {str(e)}")
        
        # é™çº§ï¼šä½¿ç”¨é¢„è®¾å¥å­
        return cls._get_fallback_message(emotion_name)

    @classmethod
    def _call_llm_api(cls, emotion_name, content):
        """
        è°ƒç”¨LLM API
        æ”¯æŒå¤šç§LLMæœåŠ¡
        """
        llm_type = os.getenv('LLM_TYPE', 'fallback')  # openai, qianwen, wenxin, deepseek, fallback
        
        if llm_type == 'openai':
            return cls._call_openai(emotion_name, content)
        elif llm_type == 'qianwen':
            return cls._call_qianwen(emotion_name, content)
        elif llm_type == 'wenxin':
            return cls._call_wenxin(emotion_name, content)
        elif llm_type == 'deepseek':
            return cls._call_deepseek(emotion_name, content)
        else:
            return {'success': False}

    @classmethod
    def _call_openai(cls, emotion_name, content):
        """è°ƒç”¨OpenAI API"""
        api_key = os.getenv('OPENAI_API_KEY')
        if not api_key:
            return {'success': False}
        
        try:
            prompt = cls.PROMPT_TEMPLATE.format(
                emotion=emotion_name,
                content=content[:200]  # é™åˆ¶é•¿åº¦
            )
            
            response = requests.post(
                'https://api.openai.com/v1/chat/completions',
                headers={
                    'Authorization': f'Bearer {api_key}',
                    'Content-Type': 'application/json'
                },
                json={
                    'model': 'gpt-3.5-turbo',
                    'messages': [
                        {'role': 'system', 'content': 'ä½ æ˜¯ä¸€ä½æ¸©æš–çš„å¿ƒç†é™ªä¼´è€…ã€‚'},
                        {'role': 'user', 'content': prompt}
                    ],
                    'max_tokens': 100,
                    'temperature': 0.8
                },
                timeout=10
            )
            
            if response.status_code == 200:
                data = response.json()
                message = data['choices'][0]['message']['content'].strip()
                return {
                    'content': message,
                    'model': 'gpt-3.5-turbo',
                    'success': True
                }
        except Exception as e:
            current_app.logger.error(f"OpenAIè°ƒç”¨å¤±è´¥: {str(e)}")
        
        return {'success': False}

    @classmethod
    def _call_qianwen(cls, emotion_name, content):
        """è°ƒç”¨é€šä¹‰åƒé—®API"""
        api_key = os.getenv('QIANWEN_API_KEY')
        if not api_key:
            return {'success': False}
        
        try:
            prompt = cls.PROMPT_TEMPLATE.format(
                emotion=emotion_name,
                content=content[:200]
            )
            
            response = requests.post(
                'https://dashscope.aliyuncs.com/api/v1/services/aigc/text-generation/generation',
                headers={
                    'Authorization': f'Bearer {api_key}',
                    'Content-Type': 'application/json'
                },
                json={
                    'model': 'qwen-turbo',
                    'input': {
                        'messages': [
                            {'role': 'system', 'content': 'ä½ æ˜¯ä¸€ä½æ¸©æš–çš„å¿ƒç†é™ªä¼´è€…ã€‚'},
                            {'role': 'user', 'content': prompt}
                        ]
                    },
                    'parameters': {
                        'max_tokens': 100
                    }
                },
                timeout=10
            )
            
            if response.status_code == 200:
                data = response.json()
                message = data['output']['text'].strip()
                return {
                    'content': message,
                    'model': 'qwen-turbo',
                    'success': True
                }
        except Exception as e:
            current_app.logger.error(f"é€šä¹‰åƒé—®è°ƒç”¨å¤±è´¥: {str(e)}")
        
        return {'success': False}

    @classmethod
    def _call_wenxin(cls, emotion_name, content):
        """è°ƒç”¨æ–‡å¿ƒä¸€è¨€API"""
        api_key = os.getenv('WENXIN_API_KEY')
        secret_key = os.getenv('WENXIN_SECRET_KEY')
        if not api_key or not secret_key:
            return {'success': False}
        
        # æ–‡å¿ƒä¸€è¨€éœ€è¦å…ˆè·å–access_token
        # è¿™é‡Œç®€åŒ–å¤„ç†ï¼Œå®é™…ä½¿ç”¨æ—¶éœ€è¦å®ç°tokenç®¡ç†
        try:
            # è·å–access_token
            token_response = requests.post(
                f'https://aip.baidubce.com/oauth/2.0/token?grant_type=client_credentials&client_id={api_key}&client_secret={secret_key}',
                timeout=5
            )
            
            if token_response.status_code == 200:
                access_token = token_response.json()['access_token']
                
                prompt = cls.PROMPT_TEMPLATE.format(
                    emotion=emotion_name,
                    content=content[:200]
                )
                
                response = requests.post(
                    f'https://aip.baidubce.com/rpc/2.0/ai_custom/v1/wenxinworkshop/chat/completions?access_token={access_token}',
                    json={
                        'messages': [
                            {'role': 'user', 'content': prompt}
                        ]
                    },
                    timeout=10
                )
                
                if response.status_code == 200:
                    data = response.json()
                    message = data['result'].strip()
                    return {
                        'content': message,
                        'model': 'wenxin',
                        'success': True
                    }
        except Exception as e:
            current_app.logger.error(f"æ–‡å¿ƒä¸€è¨€è°ƒç”¨å¤±è´¥: {str(e)}")
        
        return {'success': False}

    @classmethod
    def _call_deepseek(cls, emotion_name, content):
        """è°ƒç”¨DeepSeek V3 API"""
        api_key = os.getenv('DEEPSEEK_API_KEY')
        if not api_key:
            return {'success': False}
        
        try:
            prompt = cls.PROMPT_TEMPLATE.format(
                emotion=emotion_name,
                content=content[:200]
            )
            
            response = requests.post(
                'https://api.deepseek.com/v1/chat/completions',
                headers={
                    'Authorization': f'Bearer {api_key}',
                    'Content-Type': 'application/json'
                },
                json={
                    'model': 'deepseek-chat',
                    'messages': [
                        {'role': 'system', 'content': 'ä½ æ˜¯ä¸€ä½æ¸©æš–çš„å¿ƒç†é™ªä¼´è€…ã€‚'},
                        {'role': 'user', 'content': prompt}
                    ],
                    'max_tokens': 100,
                    'temperature': 0.8
                },
                timeout=15
            )
            
            if response.status_code == 200:
                data = response.json()
                message = data['choices'][0]['message']['content'].strip()
                return {
                    'content': message,
                    'model': 'deepseek-chat',
                    'success': True
                }
        except Exception as e:
            current_app.logger.error(f"DeepSeekè°ƒç”¨å¤±è´¥: {str(e)}")
        
        return {'success': False}

    @classmethod
    def analyze_emotion_from_text(cls, text):
        """
        ä½¿ç”¨DeepSeek V3åˆ†ææ–‡æœ¬æƒ…ç»ªï¼ˆç»“åˆä¸“ä¸šsentimentè¯å…¸ä¼˜åŒ–ç‰ˆï¼‰
        è¿”å›æƒ…ç»ªæ ‡ç­¾åç§°
        
        Args:
            text: å¾…åˆ†æçš„æ–‡æœ¬å†…å®¹
            
        Returns:
            str: æƒ…ç»ªæ ‡ç­¾åç§°ï¼Œå¦‚ 'å¼€å¿ƒ', 'éš¾è¿‡', 'å¹³é™' ç­‰
        """
        if not text or len(text.strip()) < 3:
            return None
        
        # ç¬¬ä¸€æ­¥ï¼šä½¿ç”¨ä¸“ä¸šsentimentè¯å…¸è¿›è¡Œå¿«é€Ÿé¢„åˆ¤æ–­
        try:
            lexicon_result = SentimentLexicon.analyze_with_lexicon(text)
            # å¦‚æœä¸“ä¸šè¯å…¸ç½®ä¿¡åº¦å¾ˆé«˜ï¼ˆ>=0.8ï¼‰ï¼Œç›´æ¥è¿”å›
            if lexicon_result and lexicon_result.get('confidence', 0) >= 0.8:
                top_emotion = max(
                    lexicon_result['emotion_scores'], 
                    key=lexicon_result['emotion_scores'].get
                ) if lexicon_result['emotion_scores'] else None
                
                if top_emotion:
                    current_app.logger.debug(
                        f"ä¸“ä¸šè¯å…¸å¿«é€Ÿè¯†åˆ«: {top_emotion}, "
                        f"ç½®ä¿¡åº¦: {lexicon_result['confidence']:.2f}"
                    )
                    return top_emotion
        except Exception as e:
            current_app.logger.warning(f"ä¸“ä¸šè¯å…¸é¢„åˆ¤æ–­å¤±è´¥: {str(e)}")
        
        api_key = os.getenv('DEEPSEEK_API_KEY')
        if not api_key:
            # å¦‚æœæ²¡æœ‰é…ç½®API Keyï¼Œä½¿ç”¨ä¸“ä¸šè¯å…¸æˆ–å…³é”®è¯åŒ¹é…
            if lexicon_result and lexicon_result['emotion_scores']:
                top_emotion = max(
                    lexicon_result['emotion_scores'], 
                    key=lexicon_result['emotion_scores'].get
                )
                return top_emotion
            return cls._match_emotion_by_keywords(text)
        
        try:
            # è·å–ç³»ç»Ÿæƒ…ç»ªæ ‡ç­¾åˆ—è¡¨
            from app_2.model.emotion_label import EmotionLabel
            system_labels = EmotionLabel.get_system_labels()
            emotion_names = [label.name for label in system_labels]
            emotion_list = 'ã€'.join(emotion_names)
            
            # æ£€æµ‹ç‰¹æ®Šæƒ…å†µ
            has_turnaround = cls._detect_turnaround_keywords(text)
            has_mixed_emotion = cls._detect_mixed_emotion_keywords(text)
            modal_info = cls._detect_modal_particles(text)
            
            # å°†ä¸“ä¸šè¯å…¸åˆ†æç»“æœèå…¥æç¤ºè¯
            lexicon_context = ""
            if lexicon_result and lexicon_result['emotion_scores']:
                sorted_emotions = sorted(
                    lexicon_result['emotion_scores'].items(),
                    key=lambda x: x[1],
                    reverse=True
                )[:3]
                
                if sorted_emotions:
                    emotion_str = 'ã€'.join([f"{name}" for name, _ in sorted_emotions])
                    lexicon_context = f"ğŸ’¡ ä¸“ä¸šè¯å…¸åˆ†ææç¤ºï¼šå€™é€‰æƒ…ç»ªå¯èƒ½æ˜¯ {emotion_str}ï¼ˆæŒ‰åŒ¹é…å¼ºåº¦æ’åºï¼‰ï¼Œä½†éœ€ç»“åˆæ–‡æœ¬ä¸Šä¸‹æ–‡ç»¼åˆåˆ†æã€‚"
            
            # æ„å»ºä¼˜åŒ–çš„æç¤ºè¯
            prompt = cls._build_emotion_analysis_prompt(
                text, emotion_list, emotion_names, 
                has_turnaround, has_mixed_emotion, modal_info,
                lexicon_context=lexicon_context
            )
            
            # è®°å½•æ£€æµ‹ç»“æœ
            if has_turnaround:
                current_app.logger.debug(
                    f"æ£€æµ‹åˆ°è½¬æŠ˜å¥å¼: {text[:50]}..., "
                    f"å°†ä½¿ç”¨è½¬æŠ˜å¥å¼å¤„ç†æç¤º"
                )
            if has_mixed_emotion:
                current_app.logger.debug(
                    f"æ£€æµ‹åˆ°æ··åˆæƒ…ç»ª: {text[:50]}..., "
                    f"å°†è¯†åˆ«ä¸º'å¾…å®š'"
                )
            if modal_info['has_particles']:
                current_app.logger.debug(
                    f"æ£€æµ‹åˆ°è¯­æ°”è¯: {text[:50]}..., "
                    f"è¯­æ°”è¯: {modal_info['particles']}, "
                    f"å¼ºåº¦è¯: {modal_info['intensity_words']}"
                )
            
            response = requests.post(
                'https://api.deepseek.com/v1/chat/completions',
                headers={
                    'Authorization': f'Bearer {api_key}',
                    'Content-Type': 'application/json'
                },
                json={
                    'model': 'deepseek-chat',
                    'messages': [
                        {'role': 'system', 'content': cls._build_system_message()},
                        {'role': 'user', 'content': prompt}
                    ],
                    'max_tokens': 20,  # å¢åŠ tokenæ•°ï¼Œå…è®¸æ›´è¯¦ç»†çš„è¾“å‡º
                    'temperature': 0.1,  # è¿›ä¸€æ­¥é™ä½æ¸©åº¦ä»¥æé«˜å‡†ç¡®æ€§å’Œä¸€è‡´æ€§
                    'top_p': 0.9,  # ä½¿ç”¨top_pé‡‡æ ·ï¼Œæé«˜ç¡®å®šæ€§
                    'frequency_penalty': 0.3,  # å‡å°‘é‡å¤
                    'presence_penalty': 0.0  # é¼“åŠ±å¤šæ ·åŒ–è¾“å‡º
                },
                timeout=20  # å¢åŠ è¶…æ—¶æ—¶é—´
            )
            
            if response.status_code == 200:
                data = response.json()
                emotion_result = data['choices'][0]['message']['content'].strip()
                
                # ä½¿ç”¨æ”¹è¿›çš„è§£ææ–¹æ³•
                emotion_name = cls._parse_emotion_result(emotion_result, emotion_names)
                
                if emotion_name:
                    # å¦‚æœä¸“ä¸šè¯å…¸ä¹Ÿæœ‰ç»“æœï¼ŒéªŒè¯ä¸€è‡´æ€§
                    if lexicon_result and lexicon_result['emotion_scores']:
                        lexicon_top = max(
                            lexicon_result['emotion_scores'], 
                            key=lexicon_result['emotion_scores'].get
                        )
                        if lexicon_top == emotion_name:
                            current_app.logger.debug(
                                f"DeepSeekå’Œä¸“ä¸šè¯å…¸ç»“æœä¸€è‡´: {emotion_name}, "
                                f"æ–‡æœ¬={text[:50]}..."
                            )
                        else:
                            current_app.logger.debug(
                                f"DeepSeek: {emotion_name}, è¯å…¸: {lexicon_top}, "
                                f"ä½¿ç”¨DeepSeekç»“æœ"
                            )
                    
                    current_app.logger.debug(
                        f"DeepSeekæƒ…ç»ªåˆ†ææˆåŠŸ: æ–‡æœ¬={text[:50]}..., "
                        f"ç»“æœ={emotion_result}, "
                        f"åŒ¹é…={emotion_name}"
                    )
                    return emotion_name
                else:
                    current_app.logger.warning(
                        f"DeepSeekæƒ…ç»ªåˆ†æç»“æœæ— æ³•åŒ¹é…: æ–‡æœ¬={text[:50]}..., "
                        f"ç»“æœ={emotion_result}"
                    )
                    # é™çº§æ–¹æ¡ˆï¼šä¼˜å…ˆä½¿ç”¨ä¸“ä¸šè¯å…¸ï¼Œå†ä½¿ç”¨å…³é”®è¯åŒ¹é…
                    if lexicon_result and lexicon_result['emotion_scores']:
                        top_emotion = max(
                            lexicon_result['emotion_scores'], 
                            key=lexicon_result['emotion_scores'].get
                        )
                        current_app.logger.debug(f"é™çº§åˆ°ä¸“ä¸šè¯å…¸: {top_emotion}")
                        return top_emotion
                    # æœ€åé™çº§åˆ°å…³é”®è¯åŒ¹é…
                    return cls._match_emotion_by_keywords(text)
            else:
                current_app.logger.error(
                    f"DeepSeek APIè°ƒç”¨å¤±è´¥: status={response.status_code}, "
                    f"response={response.text[:200]}"
                )
                # é™çº§æ–¹æ¡ˆï¼šä¼˜å…ˆä½¿ç”¨ä¸“ä¸šè¯å…¸
                if lexicon_result and lexicon_result['emotion_scores']:
                    top_emotion = max(
                        lexicon_result['emotion_scores'], 
                        key=lexicon_result['emotion_scores'].get
                    )
                    return top_emotion
                return cls._match_emotion_by_keywords(text)
            
        except requests.Timeout:
            current_app.logger.error(f"DeepSeekæƒ…ç»ªåˆ†æè¶…æ—¶: {text[:50]}...")
            # è¶…æ—¶é™çº§ï¼šä¼˜å…ˆä½¿ç”¨ä¸“ä¸šè¯å…¸
            if lexicon_result and lexicon_result['emotion_scores']:
                top_emotion = max(
                    lexicon_result['emotion_scores'], 
                    key=lexicon_result['emotion_scores'].get
                )
                return top_emotion
            return cls._match_emotion_by_keywords(text)
        except Exception as e:
            current_app.logger.error(f"DeepSeekæƒ…ç»ªåˆ†æå¤±è´¥: {str(e)}")
            # å¼‚å¸¸é™çº§ï¼šä¼˜å…ˆä½¿ç”¨ä¸“ä¸šè¯å…¸
            if lexicon_result and lexicon_result['emotion_scores']:
                top_emotion = max(
                    lexicon_result['emotion_scores'], 
                    key=lexicon_result['emotion_scores'].get
                )
                return top_emotion
            return cls._match_emotion_by_keywords(text)
        
        return None
    
    @classmethod
    def _build_system_message(cls):
        """æ„å»ºç³»ç»Ÿæ¶ˆæ¯ï¼Œæä¾›æ›´ä¸“ä¸šçš„è§’è‰²å®šä¹‰"""
        return """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æƒ…ç»ªåˆ†æä¸“å®¶ï¼Œæ“…é•¿ä»ä¸­æ–‡æ–‡æœ¬ä¸­å‡†ç¡®è¯†åˆ«ä½œè€…çš„æƒ…ç»ªçŠ¶æ€ã€‚

ä½ çš„ä»»åŠ¡ï¼š
1. ä»”ç»†åˆ†ææ–‡æœ¬çš„è¯­è¨€é£æ ¼ã€ç”¨è¯ã€è¯­æ°”
2. è¯†åˆ«ä½œè€…çš„çœŸå®æƒ…ç»ªçŠ¶æ€
3. ä»ç»™å®šçš„æƒ…ç»ªæ ‡ç­¾ä¸­é€‰æ‹©æœ€åŒ¹é…çš„ä¸€ä¸ª
4. åªè¿”å›æƒ…ç»ªæ ‡ç­¾åç§°ï¼Œä¸è¦æœ‰å…¶ä»–è§£é‡Š

æƒ…ç»ªæ ‡ç­¾å®šä¹‰ï¼š
- å¼€å¿ƒï¼šå–œæ‚¦ã€æ„‰å¿«ã€å…´å¥‹ã€æ»¡è¶³
- éš¾è¿‡ï¼šæ‚²ä¼¤ã€å¤±è½ã€æ²®ä¸§ã€ç—›è‹¦
- ç„¦è™‘ï¼šæ‹…å¿ƒã€ä¸å®‰ã€ç´§å¼ ã€å‹åŠ›
- æ„¤æ€’ï¼šç”Ÿæ°”ã€ä¸æ»¡ã€æš´èºã€æ¼ç«
- å¹³é™ï¼šå®é™ã€æ·¡å®šã€ä»å®¹ã€å¹³å’Œ
- ç–²æƒ«ï¼šç´¯ã€ç–²å€¦ã€åŠ³ç´¯ã€ä¹åŠ›
- æ„ŸåŠ¨ï¼šæ„Ÿæ¿€ã€æ¸©æš–ã€è§¦åŠ¨ã€åŠ¨å®¹
- å…´å¥‹ï¼šæ¿€åŠ¨ã€æŒ¯å¥‹ã€çƒ­æƒ…ã€å……æ»¡æ´»åŠ›
- æœŸå¾…ï¼šæœŸæœ›ã€ç›¼æœ›ã€å¸Œæœ›ã€ç­‰å¾…
- å­¤ç‹¬ï¼šå¯‚å¯ã€å­¤å•ã€ç‹¬è‡ªã€å­¤ç«‹

åˆ†æåŸåˆ™ï¼š
- ä¼˜å…ˆè€ƒè™‘æ–‡æœ¬çš„ä¸»è¦æƒ…ç»ª
- æ³¨æ„è¯­å¢ƒå’Œéšå«çš„æƒ…ç»ª
- **æ³¨æ„è¯­æ°”è¯ï¼ˆå•Šã€å‘€ã€å‘¢ã€å§ç­‰ï¼‰å’Œå¼ºåº¦è¯ï¼ˆçœŸçš„ã€å¤ªã€ç‰¹åˆ«ç­‰ï¼‰ï¼Œå®ƒä»¬å¯ä»¥å¸®åŠ©åˆ¤æ–­æƒ…ç»ªå¼ºåº¦**
- **ç‰¹åˆ«æ³¨æ„è½¬æŠ˜å¥å¼ï¼ˆå¦‚"è™½ç„¶...ä½†æ˜¯..."ã€"è™½ç„¶...è¿˜æ˜¯..."ï¼‰ï¼šè½¬æŠ˜åçš„å†…å®¹è¡¨è¾¾çœŸå®æƒ…ç»ª**
- å¦‚æœæ–‡æœ¬æƒ…ç»ªä¸æ˜æ˜¾æˆ–æ··åˆï¼Œé€‰æ‹©æœ€æ¥è¿‘çš„æ ‡ç­¾

è¯­æ°”è¯åˆ†æï¼š
- è¯­æ°”è¯ï¼ˆå•Šã€å‘€ã€å‘¢ã€å§ã€å—ã€å“¦ç­‰ï¼‰å¯ä»¥è¡¨è¾¾æƒ…ç»ªçš„è¯­æ°”å’Œå¼ºåº¦
- å¼ºåº¦è¯ï¼ˆçœŸçš„ã€å¤ªã€å¥½ã€ç‰¹åˆ«ã€éå¸¸ç­‰ï¼‰è¡¨ç¤ºæƒ…ç»ªçš„å¼ºçƒˆç¨‹åº¦
- ç»“åˆè¯­æ°”è¯å’Œå¼ºåº¦è¯å¯ä»¥æ›´å‡†ç¡®åœ°åˆ¤æ–­æƒ…ç»ªç±»å‹å’Œå¼ºåº¦

è½¬æŠ˜å¥å¼å¤„ç†ï¼š
- "è™½ç„¶Xï¼ˆè´Ÿé¢ï¼‰ï¼Œä½†æ˜¯Yï¼ˆæ­£é¢æƒ…ç»ªï¼‰" â†’ è¯†åˆ«ä¸ºæ­£é¢æƒ…ç»ªï¼ˆè½¬æŠ˜åçš„æƒ…ç»ªï¼‰
- "è™½ç„¶Xï¼ˆè´Ÿé¢ï¼‰ï¼Œä½†æ˜¯Yï¼ˆæ­£é¢è¡Œä¸ºï¼‰" â†’ è¯†åˆ«ä¸ºè´Ÿé¢æƒ…ç»ªï¼ˆè½¬æŠ˜å‰çš„æƒ…ç»ªï¼‰
- "è™½ç„¶è¡¨é¢å¹³é™ï¼Œä½†å†…å¿ƒè¿˜æ˜¯æœ‰ç‚¹ä¸å®‰" â†’ è¯†åˆ«ä¸º"ç„¦è™‘"ï¼ˆè½¬æŠ˜åçš„çœŸå®æƒ…ç»ªï¼‰

æ··åˆæƒ…ç»ªå¤„ç†ï¼š
- "åˆ...åˆ..."ã€"æ—¢...åˆ..." â†’ è¯†åˆ«ä¸º"å¾…å®š"ï¼ˆæ··åˆæƒ…ç»ªï¼‰
- "ä¸çŸ¥é“æ˜¯ä»€ä¹ˆæ„Ÿè§‰"ã€"å¿ƒæƒ…å¾ˆå¤æ‚" â†’ è¯†åˆ«ä¸º"å¾…å®š"ï¼ˆä¸ç¡®å®šçŠ¶æ€ï¼‰"""
    
    @classmethod
    def _build_emotion_analysis_prompt(cls, text, emotion_list, emotion_names, 
                                       has_turnaround=False, has_mixed_emotion=False, 
                                       modal_info=None, lexicon_context=""):
        """
        æ„å»ºä¼˜åŒ–çš„æƒ…ç»ªåˆ†ææç¤ºè¯
        
        Args:
            text: æ–‡æœ¬å†…å®¹
            emotion_list: æƒ…ç»ªæ ‡ç­¾åˆ—è¡¨ï¼ˆå­—ç¬¦ä¸²ï¼‰
            emotion_names: æƒ…ç»ªæ ‡ç­¾åç§°åˆ—è¡¨
            has_turnaround: æ˜¯å¦æ£€æµ‹åˆ°è½¬æŠ˜å¥å¼
            has_mixed_emotion: æ˜¯å¦æ£€æµ‹åˆ°æ··åˆæƒ…ç»ª
            modal_info: è¯­æ°”è¯ä¿¡æ¯
            lexicon_context: ä¸“ä¸šè¯å…¸åˆ†æä¸Šä¸‹æ–‡ï¼ˆå¯é€‰ï¼‰
        """
        if modal_info is None:
            modal_info = {'has_particles': False, 'particles': [], 'intensity_words': []}
        
        # æ¸…ç†æ–‡æœ¬ï¼Œç§»é™¤å¤šä½™ç©ºæ ¼å’Œæ¢è¡Œ
        text_clean = ' '.join(text.split())
        
        # é™åˆ¶æ–‡æœ¬é•¿åº¦ï¼Œä½†ä¿ç•™æ›´å¤šä¸Šä¸‹æ–‡
        text_truncated = text_clean[:800] if len(text_clean) > 800 else text_clean
        
        # ä¼˜å…ˆå¤„ç†æ··åˆæƒ…ç»ª
        if has_mixed_emotion:
            mixed_emotion_instruction = """

âš ï¸ é‡è¦æç¤ºï¼šæ£€æµ‹åˆ°æ··åˆæƒ…ç»ªè¡¨è¾¾ï¼ˆå¦‚"åˆ...åˆ..."ã€"æ—¢...åˆ..."ã€"ä¸çŸ¥é“æ˜¯ä»€ä¹ˆæ„Ÿè§‰"ç­‰ï¼‰ã€‚
è¯·ç‰¹åˆ«æ³¨æ„ï¼šå½“æ–‡æœ¬æ˜ç¡®è¡¨è¾¾å‡ºå¤šç§çŸ›ç›¾æƒ…ç»ªæˆ–ä¸ç¡®å®šçš„æ„Ÿè§‰æ—¶ï¼Œåº”è¯¥è¯†åˆ«ä¸º"å¾…å®š"ã€‚
ä¾‹å¦‚ï¼š
- "åˆå¼€å¿ƒåˆéš¾è¿‡ï¼Œä¸çŸ¥é“æ˜¯ä»€ä¹ˆæ„Ÿè§‰" â†’ åº”è¯¥è¯†åˆ«ä¸º"å¾…å®š"ï¼ˆæ··åˆæƒ…ç»ªï¼Œä¸ç¡®å®šï¼‰
- "ä»Šå¤©å‘ç”Ÿäº†å¾ˆå¤šäº‹æƒ…ï¼Œå¿ƒæƒ…å¾ˆå¤æ‚" â†’ åº”è¯¥è¯†åˆ«ä¸º"å¾…å®š"ï¼ˆå¤æ‚æƒ…ç»ªï¼‰
- "æ—¢å…´å¥‹åˆç´§å¼ ï¼Œè¯´ä¸æ¸…æ˜¯ä»€ä¹ˆæ„Ÿè§‰" â†’ åº”è¯¥è¯†åˆ«ä¸º"å¾…å®š"ï¼ˆæ··åˆæƒ…ç»ªï¼‰

è¯·ç›´æ¥è¿”å›"å¾…å®š"ã€‚

"""
            return f"""è¯·åˆ†æä»¥ä¸‹æ–‡æœ¬å†…å®¹ï¼Œåˆ¤æ–­ä½œè€…çš„æƒ…ç»ªçŠ¶æ€ã€‚

å¯é€‰çš„æƒ…ç»ªæ ‡ç­¾ï¼š{emotion_list}{mixed_emotion_instruction}
æ–‡æœ¬å†…å®¹ï¼š{text_truncated}

è¯·ç›´æ¥è¿”å›æƒ…ç»ªæ ‡ç­¾åç§°ï¼ˆå¦‚æœæ˜¯æ··åˆæƒ…ç»ªï¼Œè¯·è¿”å›"å¾…å®š"ï¼‰ï¼š"""
        
        # æ·»åŠ few-shotç¤ºä¾‹ï¼ˆå¦‚æœæ–‡æœ¬å¾ˆçŸ­ï¼Œæä¾›æ›´å…·ä½“çš„æŒ‡å¯¼ï¼‰
        few_shot_examples = ""
        if len(text_clean) < 50:
            few_shot_examples = """

ç¤ºä¾‹ï¼š
æ–‡æœ¬ï¼š"ä»Šå¤©å¤©æ°”çœŸå¥½ï¼Œå¿ƒæƒ…ä¹Ÿä¸é”™ï¼"
æƒ…ç»ªï¼šå¼€å¿ƒ

æ–‡æœ¬ï¼š"æœ€è¿‘å·¥ä½œå‹åŠ›å¾ˆå¤§ï¼Œæ€»æ˜¯ç¡ä¸å¥½"
æƒ…ç»ªï¼šç„¦è™‘

æ–‡æœ¬ï¼š"ä¸€ä¸ªäººåœ¨å®¶ï¼Œæ„Ÿè§‰æœ‰ç‚¹å­¤å•"
æƒ…ç»ªï¼šå­¤ç‹¬

æ–‡æœ¬ï¼š"æ„Ÿè°¢æœ‹å‹çš„å¸®åŠ©ï¼ŒçœŸçš„å¾ˆæ„ŸåŠ¨"
æƒ…ç»ªï¼šæ„ŸåŠ¨

"""
        
        # è¯­æ°”è¯åˆ†ææç¤º
        modal_instruction = ""
        if modal_info['has_particles']:
            particles_str = 'ã€'.join(set(modal_info['particles'])) if modal_info['particles'] else ''
            intensity_str = 'ã€'.join(set(modal_info['intensity_words'])) if modal_info['intensity_words'] else ''
            
            modal_instruction = """

ğŸ’¡ è¯­æ°”è¯æç¤ºï¼šæ£€æµ‹åˆ°è¯­æ°”è¯å’Œå¼ºåº¦è¯ï¼Œè¿™äº›å¯ä»¥å¸®åŠ©åˆ¤æ–­æƒ…ç»ªå¼ºåº¦ã€‚
"""
            if particles_str:
                modal_instruction += f"\næ£€æµ‹åˆ°çš„è¯­æ°”è¯ï¼š{particles_str}\n"
            if intensity_str:
                modal_instruction += f"\næ£€æµ‹åˆ°çš„å¼ºåº¦è¯ï¼š{intensity_str}\n"
            
            modal_instruction += """
è¯­æ°”è¯çš„ä½œç”¨ï¼š
- "å•Š"ã€"å‘€"ã€"å‘¢"ã€"å§"ç­‰è¯­æ°”è¯å¯ä»¥è¡¨è¾¾ä¸åŒçš„æƒ…ç»ªè¯­æ°”å’Œå¼ºåº¦
- "çœŸçš„"ã€"å¤ª"ã€"ç‰¹åˆ«"ã€"éå¸¸"ç­‰å¼ºåº¦è¯è¡¨ç¤ºæƒ…ç»ªçš„å¼ºçƒˆç¨‹åº¦

ä¾‹å¦‚ï¼š
- "ä»Šå¤©çœŸçš„å¤ªå¥½å•¦ï¼" â†’ è¯­æ°”è¯"å•¦"å’Œå¼ºåº¦è¯"çœŸçš„"ã€"å¤ª"è¡¨ç¤ºå¼ºçƒˆçš„å¼€å¿ƒ
- "æˆ‘å¥½éš¾è¿‡å•Š..." â†’ è¯­æ°”è¯"å•Š"å’Œå¼ºåº¦è¯"å¥½"è¡¨ç¤ºè¾ƒå¼ºçš„éš¾è¿‡
- "å¤ªç„¦è™‘äº†..." â†’ å¼ºåº¦è¯"å¤ª"è¡¨ç¤ºå¾ˆå¼ºçš„ç„¦è™‘
- "ç‰¹åˆ«æ„ŸåŠ¨å‘¢ï¼" â†’ å¼ºåº¦è¯"ç‰¹åˆ«"å’Œè¯­æ°”è¯"å‘¢"è¡¨ç¤ºå¼ºçƒˆçš„æ„ŸåŠ¨

è¯·ç»“åˆè¯­æ°”è¯å’Œå¼ºåº¦è¯æ¥æ›´å‡†ç¡®åœ°åˆ¤æ–­æƒ…ç»ªç±»å‹å’Œå¼ºåº¦ã€‚

"""
        
        # è½¬æŠ˜å¥å¼å¤„ç†æç¤ºï¼ˆéœ€è¦åŒºåˆ†æƒ…ç»ªæè¿°ã€ç§¯æè¡Œä¸ºå’Œæ¶ˆæè¡Œä¸ºï¼‰
        turnaround_instruction = ""
        if has_turnaround:
            # æ£€æµ‹æ˜¯å¦åŒ…å«ç§¯æè¡Œä¸º
            positive_actions = [
                'å…‹æœ', 'åšæŒ', 'åŠªåŠ›', 'é¢å¯¹', 'æˆ˜èƒœ', 'åº”å¯¹', 'æŒ‘æˆ˜', 
                'ç»§ç»­', 'å‰è¿›', 'å¥‹æ–—', 'æ‹¼æ', 'è§£å†³', 'çªç ´', 'è¿›å–',
                'å‹‡æ•¢', 'åšå¼º', 'åšéŸ§', 'ä¸å±ˆ', 'ä¸æŒ '
            ]
            has_positive_action = any(action in text for action in positive_actions)
            
            turnaround_instruction = """

âš ï¸ é‡è¦æç¤ºï¼šæ£€æµ‹åˆ°è½¬æŠ˜å¥å¼ï¼ˆå¦‚"è™½ç„¶...ä½†æ˜¯..."ã€"è™½ç„¶...è¿˜æ˜¯..."ç­‰ï¼‰ã€‚
è¯·ç‰¹åˆ«æ³¨æ„ï¼šéœ€è¦åŒºåˆ†è½¬æŠ˜åçš„å†…å®¹æ˜¯æƒ…ç»ªæè¿°ã€ç§¯æè¡Œä¸ºè¿˜æ˜¯æ¶ˆæè¡Œä¸ºã€‚

å¤„ç†è§„åˆ™ï¼š
1. **å¦‚æœè½¬æŠ˜åæ˜¯æƒ…ç»ªæè¿°**ï¼šä¼˜å…ˆè¯†åˆ«è½¬æŠ˜åçš„æƒ…ç»ª
   - "è™½ç„¶å¾ˆç´¯ï¼Œä½†æ˜¯æ„Ÿè§‰å¾ˆå……å®" â†’ åº”è¯¥è¯†åˆ«ä¸º"å¼€å¿ƒ"ï¼ˆè½¬æŠ˜åçš„æ­£é¢æƒ…ç»ªï¼šå……å®ï¼‰
   - "è™½ç„¶è¡¨é¢å¹³é™ï¼Œä½†å†…å¿ƒè¿˜æ˜¯æœ‰ç‚¹ä¸å®‰" â†’ åº”è¯¥è¯†åˆ«ä¸º"ç„¦è™‘"ï¼ˆè½¬æŠ˜åçš„çœŸå®æƒ…ç»ªï¼šä¸å®‰ï¼‰

2. **å¦‚æœè½¬æŠ˜åæ˜¯ç§¯æè¡Œä¸º**ï¼šè¯†åˆ«ä¸ºç§¯ææƒ…ç»ªï¼ˆæœŸå¾…æˆ–å¼€å¿ƒï¼‰
   - "è™½ç„¶å¾ˆç´¯ï¼Œä½†è¿˜æ˜¯ä¼šåšæŒä¸‹å»" â†’ åº”è¯¥è¯†åˆ«ä¸º"æœŸå¾…"ï¼ˆè½¬æŠ˜åæ˜¯ç§¯æè¡Œä¸ºï¼šåšæŒï¼Œè¡¨è¾¾ç§¯ææ€åº¦ï¼‰
   - "è™½ç„¶é¢ä¸´æŒ‘æˆ˜ï¼Œä½†æˆ‘ä¼šåŠªåŠ›åº”å¯¹" â†’ åº”è¯¥è¯†åˆ«ä¸º"æœŸå¾…"ï¼ˆè½¬æŠ˜åæ˜¯ç§¯æè¡Œä¸ºï¼šåŠªåŠ›åº”å¯¹ï¼Œè¡¨è¾¾ç§¯ææ€åº¦ï¼‰
   
   ç§¯æè¡Œä¸ºå…³é”®è¯ï¼šå…‹æœã€åšæŒã€åŠªåŠ›ã€é¢å¯¹ã€æˆ˜èƒœã€åº”å¯¹ã€æŒ‘æˆ˜ã€ç»§ç»­ã€å‰è¿›ã€å¥‹æ–—ã€æ‹¼æã€è§£å†³ã€çªç ´ç­‰
   
3. **å¦‚æœè½¬æŠ˜åæ˜¯æ¶ˆæè¡Œä¸º**ï¼šè¯†åˆ«è½¬æŠ˜å‰çš„æƒ…ç»ªçŠ¶æ€
   - "è™½ç„¶æœ‰ç‚¹éš¾è¿‡ï¼Œä½†è¿˜æ˜¯è¦åšæŒä¸‹å»" â†’ å¦‚æœè½¬æŠ˜å‰éš¾è¿‡å¾ˆæ˜æ˜¾ä¸”è½¬æŠ˜ååªæ˜¯è¡Œä¸ºè€Œéæƒ…ç»ªè½¬å˜ï¼Œä»å¯è¯†åˆ«ä¸º"éš¾è¿‡"
   - "è™½ç„¶å¾ˆç„¦è™‘ï¼Œä½†è¿˜æ˜¯ä¼šåŠªåŠ›é¢å¯¹" â†’ å¦‚æœè½¬æŠ˜å‰ç„¦è™‘å¾ˆæ˜æ˜¾ï¼Œä»å¯è¯†åˆ«ä¸º"ç„¦è™‘"
   - "è™½ç„¶å¾ˆå®³æ€•ï¼Œä½†è¿˜æ˜¯é€€ç¼©äº†" â†’ åº”è¯¥è¯†åˆ«ä¸º"ç„¦è™‘"ï¼ˆè½¬æŠ˜å‰æ˜¯æƒ…ç»ªï¼šå®³æ€•ï¼Œè½¬æŠ˜åæ˜¯æ¶ˆæè¡Œä¸ºï¼šé€€ç¼©ï¼‰

åˆ¤æ–­æ ‡å‡†ï¼š
- è½¬æŠ˜åæ˜¯æƒ…ç»ªè¯æ±‡ï¼ˆå¼€å¿ƒã€éš¾è¿‡ã€ç„¦è™‘ã€å¹³é™ç­‰ï¼‰â†’ è¯†åˆ«è½¬æŠ˜åçš„æƒ…ç»ª
- è½¬æŠ˜åæ˜¯ç§¯æè¡Œä¸ºè¯æ±‡ï¼ˆå…‹æœã€åšæŒã€åŠªåŠ›ã€é¢å¯¹ã€æˆ˜èƒœç­‰ï¼‰â†’ è¯†åˆ«ä¸º"æœŸå¾…"ï¼ˆè¡¨è¾¾ç§¯ææ€åº¦ï¼‰
- è½¬æŠ˜åæ˜¯æ¶ˆæè¡Œä¸ºè¯æ±‡ï¼ˆæ”¾å¼ƒã€é€ƒé¿ã€é€€ç¼©ç­‰ï¼‰â†’ è¯†åˆ«è½¬æŠ˜å‰çš„æƒ…ç»ª

è¯·ä»”ç»†åˆ†æè½¬æŠ˜å‰åçš„å†…å®¹ç±»å‹æ¥ç¡®å®šæƒ…ç»ªçŠ¶æ€ã€‚

"""
        
        # æ·»åŠ ä¸“ä¸šè¯å…¸ä¸Šä¸‹æ–‡ï¼ˆå¦‚æœæä¾›ï¼‰
        lexicon_section = ""
        if lexicon_context:
            lexicon_section = f"\n{lexicon_context}"
        
        # æ£€æµ‹å¼ºçƒˆæ„¤æ€’è¯æ±‡å¹¶æ·»åŠ æç¤º
        anger_instruction = ""
        anger_keywords = ['æ¼ç«', 'æ„¤æ€’', 'ç”Ÿæ°”', 'æ€’ç«', 'æ°”æ„¤', 'æš´èº', 'å‘ç«', 'ä¸æ»¡', 'ç«å¤§']
        has_strong_anger = any(keyword in text_truncated for keyword in anger_keywords)
        
        if has_strong_anger:
            anger_instruction = """

ğŸ”¥ é‡è¦æç¤ºï¼šæ£€æµ‹åˆ°å¼ºçƒˆçš„æ„¤æ€’æƒ…ç»ªè¯æ±‡ï¼ˆå¦‚"æ¼ç«"ã€"æ„¤æ€’"ã€"ç”Ÿæ°”"ç­‰ï¼‰ã€‚
è¯·ç‰¹åˆ«æ³¨æ„ï¼šè¿™äº›è¯æ±‡æ˜ç¡®è¡¨è¾¾æ„¤æ€’æƒ…ç»ªï¼Œåº”è¯¥è¯†åˆ«ä¸º"æ„¤æ€’"ã€‚
ä¾‹å¦‚ï¼š
- "çœ‹åˆ°ä¸åˆç†çš„ç°è±¡ï¼Œå¾ˆæ¼ç«" â†’ åº”è¯¥è¯†åˆ«ä¸º"æ„¤æ€’"ï¼ˆ"æ¼ç«"æ˜¯å¼ºçƒˆæ„¤æ€’æƒ…ç»ªï¼‰
- "è¢«äººè¯¯è§£äº†ï¼ŒçœŸçš„å¾ˆç”Ÿæ°”" â†’ åº”è¯¥è¯†åˆ«ä¸º"æ„¤æ€’"ï¼ˆ"ç”Ÿæ°”"æ˜¯æ„¤æ€’æƒ…ç»ªï¼‰
- "çœ‹åˆ°ä¸å…¬å¹³çš„äº‹æƒ…ï¼Œéå¸¸æ„¤æ€’" â†’ åº”è¯¥è¯†åˆ«ä¸º"æ„¤æ€’"ï¼ˆ"æ„¤æ€’"æ˜¯æ˜ç¡®çš„æ„¤æ€’æƒ…ç»ªï¼‰

è¯·ç›´æ¥è¯†åˆ«ä¸º"æ„¤æ€’"ã€‚

"""
        
        prompt = f"""è¯·åˆ†æä»¥ä¸‹æ–‡æœ¬å†…å®¹ï¼Œåˆ¤æ–­ä½œè€…çš„æƒ…ç»ªçŠ¶æ€ã€‚

å¯é€‰çš„æƒ…ç»ªæ ‡ç­¾ï¼š{emotion_list}{lexicon_section}{few_shot_examples}{modal_instruction}{turnaround_instruction}{anger_instruction}
æ–‡æœ¬å†…å®¹ï¼š{text_truncated}

è¦æ±‚ï¼š
1. ä»”ç»†åˆ†ææ–‡æœ¬çš„æ•´ä½“æƒ…ç»ªå€¾å‘
2. æ³¨æ„è¯­æ°”è¯å’Œå¼ºåº¦è¯ï¼Œå®ƒä»¬å¯ä»¥å¸®åŠ©åˆ¤æ–­æƒ…ç»ªå¼ºåº¦
3. ç‰¹åˆ«æ³¨æ„è½¬æŠ˜å¥å¼ï¼Œä¼˜å…ˆè€ƒè™‘è½¬æŠ˜åçš„æƒ…ç»ª
4. ä»å¯é€‰çš„æƒ…ç»ªæ ‡ç­¾ä¸­é€‰æ‹©ä¸€ä¸ªæœ€åŒ¹é…çš„
5. åªè¿”å›æƒ…ç»ªæ ‡ç­¾åç§°ï¼Œæ ¼å¼ï¼šæƒ…ç»ªæ ‡ç­¾åç§°
6. ä¸è¦åŒ…å«æ ‡ç‚¹ç¬¦å·ã€è§£é‡Šæˆ–å…¶ä»–å†…å®¹

è¯·ç›´æ¥è¿”å›æƒ…ç»ªæ ‡ç­¾åç§°ï¼š"""
        
        return prompt
    
    @classmethod
    def _detect_turnaround_keywords(cls, text):
        """
        æ£€æµ‹æ–‡æœ¬ä¸­æ˜¯å¦åŒ…å«è½¬æŠ˜å…³é”®è¯
        
        Returns:
            bool: æ˜¯å¦åŒ…å«è½¬æŠ˜å…³é”®è¯
        """
        # è½¬æŠ˜å…³é”®è¯åˆ—è¡¨
        turnaround_keywords = [
            'è™½ç„¶', 'å°½ç®¡', 'å›ºç„¶', 'è™½è¯´',
            'ä½†æ˜¯', 'ä½†', 'å¯æ˜¯', 'ç„¶è€Œ', 'å´', 'ä¸è¿‡', 'åªæ˜¯',
            'è¿˜æ˜¯', 'ä¾ç„¶', 'ä»ç„¶', 'ä¾æ—§',
            'å³ä½¿', 'å³ä¾¿', 'çºµç„¶', 'çºµä½¿',
            'å³ä½¿...ä¹Ÿ', 'å³ä½¿...è¿˜æ˜¯',
            'è™½ç„¶...ä½†æ˜¯', 'è™½ç„¶...ä½†', 'è™½ç„¶...å¯æ˜¯', 'è™½ç„¶...å´',
            'å°½ç®¡...ä½†æ˜¯', 'å°½ç®¡...ä½†', 'å°½ç®¡...å¯æ˜¯',
            'å›ºç„¶...ä½†æ˜¯', 'è™½è¯´...ä½†æ˜¯'
        ]
        
        for keyword in turnaround_keywords:
            if keyword in text:
                return True
        
        return False
    
    @classmethod
    def _detect_mixed_emotion_keywords(cls, text):
        """
        æ£€æµ‹æ–‡æœ¬ä¸­æ˜¯å¦åŒ…å«æ··åˆæƒ…ç»ªå…³é”®è¯
        
        Returns:
            bool: æ˜¯å¦åŒ…å«æ··åˆæƒ…ç»ªå…³é”®è¯
        """
        import re
        
        # æ··åˆæƒ…ç»ªæ¨¡å¼åˆ—è¡¨
        mixed_emotion_patterns = [
            r'åˆ.*åˆ',  # åˆå¼€å¿ƒåˆéš¾è¿‡
            r'æ—¢.*åˆ',  # æ—¢å…´å¥‹åˆç´§å¼ 
            r'ä¹Ÿ.*ä¹Ÿ',  # ä¹Ÿå¼€å¿ƒä¹Ÿéš¾è¿‡
            r'åŒæ—¶.*',  # åŒæ—¶æ„Ÿåˆ°
            r'éƒ½æœ‰.*',  # éƒ½æœ‰
            r'ä¸çŸ¥é“æ˜¯ä»€ä¹ˆ.*æ„Ÿè§‰',  # ä¸çŸ¥é“æ˜¯ä»€ä¹ˆæ„Ÿè§‰
            r'è¯´ä¸æ¸….*æ„Ÿè§‰',  # è¯´ä¸æ¸…æ˜¯ä»€ä¹ˆæ„Ÿè§‰
            r'è¯´ä¸å‡ºæ¥.*æ„Ÿè§‰',  # è¯´ä¸å‡ºæ¥æ˜¯ä»€ä¹ˆæ„Ÿè§‰
            r'ä¸çŸ¥é“æ˜¯.*æ„Ÿè§‰',  # ä¸çŸ¥é“æ˜¯å¼€å¿ƒè¿˜æ˜¯éš¾è¿‡
            r'å¿ƒæƒ….*å¤æ‚',  # å¿ƒæƒ…å¾ˆå¤æ‚
            r'æ„Ÿè§‰.*å¤æ‚',  # æ„Ÿè§‰å¾ˆå¤æ‚
            r'å¿ƒæƒ….*çŸ›ç›¾',  # å¿ƒæƒ…å¾ˆçŸ›ç›¾
            r'æƒ…ç»ª.*çŸ›ç›¾',  # æƒ…ç»ªå¾ˆçŸ›ç›¾
            r'çº ç»“.*æ„Ÿè§‰',  # çº ç»“çš„æ„Ÿè§‰
        ]
        
        # ç®€å•å…³é”®è¯åˆ—è¡¨ï¼ˆä¸éœ€è¦æ­£åˆ™ï¼‰
        simple_keywords = [
            'å¿ƒæƒ…å¾ˆå¤æ‚', 'æƒ…ç»ªå¾ˆå¤æ‚', 'æ„Ÿè§‰å¾ˆå¤æ‚',
            'çŸ›ç›¾çš„å¿ƒæƒ…', 'çŸ›ç›¾çš„æƒ…ç»ª', 'çŸ›ç›¾çš„æ„Ÿè§‰',
            'è¯´ä¸æ¸…', 'è¯´ä¸å‡ºæ¥', 'ä¸çŸ¥é“æ˜¯ä»€ä¹ˆ'
        ]
        
        # æ£€æŸ¥ç®€å•å…³é”®è¯
        for keyword in simple_keywords:
            if keyword in text:
                return True
        
        # æ£€æŸ¥æ­£åˆ™æ¨¡å¼
        for pattern in mixed_emotion_patterns:
            if re.search(pattern, text):
                return True
        
        return False
    
    @classmethod
    def _detect_modal_particles(cls, text):
        """
        æ£€æµ‹æ–‡æœ¬ä¸­æ˜¯å¦åŒ…å«è¯­æ°”è¯
        
        Returns:
            dict: {
                'has_particles': bool,  # æ˜¯å¦åŒ…å«è¯­æ°”è¯
                'particles': list,      # æ£€æµ‹åˆ°çš„è¯­æ°”è¯åˆ—è¡¨
                'intensity_words': list # å¼ºåº¦è¯åˆ—è¡¨
            }
        """
        import re
        
        # è¯­æ°”è¯åˆ—è¡¨ï¼ˆè¡¨è¾¾æƒ…ç»ªçš„è¯­æ°”ï¼‰
        modal_particles = [
            'å•Š', 'å‘€', 'å‘¢', 'å§', 'å—', 'å“¦', 'å–”', 'å—¯',
            'å”‰', 'å“', 'å’¦', 'å“‡', 'å–”', 'å™¢', 'å“¼', 'å˜¿',
            'å“ˆ', 'å‘µ', 'å˜»', 'å˜˜', 'å‘€', 'å˜', 'å’¯', 'å•¦',
            'å˜›', 'å–½', 'å‘', 'å“¦', 'å–”', 'å™¢', 'å‘—', 'å’§'
        ]
        
        # å¼ºåº¦è¯åˆ—è¡¨ï¼ˆå¢å¼ºæƒ…ç»ªå¼ºåº¦ï¼‰
        intensity_words = [
            'çœŸçš„', 'å¤ª', 'å¥½', 'ç‰¹åˆ«', 'éå¸¸', 'è¶…çº§', 'æå…¶',
            'æ ¼å¤–', 'ååˆ†', 'ç›¸å½“', 'å¾ˆ', 'æŒº', 'è›®', 'é¢‡ä¸º',
            'ç®€ç›´', 'å®Œå…¨', 'æ ¹æœ¬', 'å®åœ¨', 'ç¡®å®', 'çš„ç¡®',
            'è¶…çº§', 'è¶…', 'å·¨', 'è¶…è¶…', 'è¶…è¶…è¶…', 'æ— æ•Œ',
            'ç»', 'è´¼', 'è¶…', 'è¶…çº§æ— æ•Œ'
        ]
        
        detected_particles = []
        detected_intensity = []
        
        # æ£€æµ‹è¯­æ°”è¯
        for particle in modal_particles:
            if particle in text:
                detected_particles.append(particle)
        
        # æ£€æµ‹å¼ºåº¦è¯
        for intensity in intensity_words:
            # ä½¿ç”¨è¯è¾¹ç•ŒåŒ¹é…ï¼Œé¿å…è¯¯åŒ¹é…
            pattern = r'\b' + re.escape(intensity) + r'\b'
            if re.search(pattern, text):
                detected_intensity.append(intensity)
        
        return {
            'has_particles': len(detected_particles) > 0 or len(detected_intensity) > 0,
            'particles': detected_particles,
            'intensity_words': detected_intensity
        }
    
    @classmethod
    def _parse_emotion_result(cls, emotion_result, emotion_names):
        """
        è§£æDeepSeekè¿”å›çš„æƒ…ç»ªåˆ†æç»“æœ
        ä½¿ç”¨æ›´æ™ºèƒ½çš„åŒ¹é…ç­–ç•¥
        """
        if not emotion_result:
            return None
        
        # æ¸…ç†ç»“æœï¼šç§»é™¤æ ‡ç‚¹ã€ç©ºæ ¼ã€æ¢è¡Œ
        emotion_clean = emotion_result.replace('ã€‚', '').replace('.', '').replace('ï¼Œ', '').replace(',', '')
        emotion_clean = emotion_clean.replace('ï¼š', '').replace(':', '').replace('ï¼š', '')
        emotion_clean = emotion_clean.strip().replace('\n', '').replace('\r', '')
        
        # 1. å®Œå…¨åŒ¹é…ï¼ˆä¼˜å…ˆï¼‰
        if emotion_clean in emotion_names:
            return emotion_clean
        
        # 2. éƒ¨åˆ†åŒ¹é…ï¼ˆå¦‚æœç»“æœåŒ…å«æƒ…ç»ªåç§°ï¼‰
        for name in emotion_names:
            if name in emotion_clean or emotion_clean in name:
                return name
        
        # 3. ç§»é™¤å¸¸è§åç¼€ååŒ¹é…
        emotion_clean_no_suffix = emotion_clean.replace('æƒ…ç»ª', '').replace('çŠ¶æ€', '').replace('æ„Ÿè§‰', '')
        if emotion_clean_no_suffix in emotion_names:
            return emotion_clean_no_suffix
        
        for name in emotion_names:
            if name in emotion_clean_no_suffix or emotion_clean_no_suffix in name:
                return name
        
        # 4. åŒä¹‰è¯åŒ¹é…ï¼ˆæ‰©å±•ï¼‰
        synonym_map = {
            'å¿«ä¹': 'å¼€å¿ƒ',
            'é«˜å…´': 'å¼€å¿ƒ',
            'æ„‰å¿«': 'å¼€å¿ƒ',
            'æ‚²ä¼¤': 'éš¾è¿‡',
            'ä¼¤å¿ƒ': 'éš¾è¿‡',
            'æ²®ä¸§': 'éš¾è¿‡',
            'æ‹…å¿ƒ': 'ç„¦è™‘',
            'ä¸å®‰': 'ç„¦è™‘',
            'ç´§å¼ ': 'ç„¦è™‘',
            'ç”Ÿæ°”': 'æ„¤æ€’',
            'æ¼ç«': 'æ„¤æ€’',
            'æ·¡å®š': 'å¹³é™',
            'å®é™': 'å¹³é™',
            'ç´¯': 'ç–²æƒ«',
            'ç–²å€¦': 'ç–²æƒ«',
            'æ„Ÿæ¿€': 'æ„ŸåŠ¨',
            'æ¸©æš–': 'æ„ŸåŠ¨',
            'æ¿€åŠ¨': 'å…´å¥‹',
            'æŒ¯å¥‹': 'å…´å¥‹',
            'æœŸæœ›': 'æœŸå¾…',
            'ç›¼æœ›': 'æœŸå¾…',
            'å¯‚å¯': 'å­¤ç‹¬',
            'å­¤å•': 'å­¤ç‹¬'
        }
        
        for synonym, emotion_name in synonym_map.items():
            if synonym in emotion_clean and emotion_name in emotion_names:
                return emotion_name
        
        return None

    @classmethod
    def _match_emotion_by_keywords(cls, text):
        """
        é€šè¿‡å…³é”®è¯åŒ¹é…æƒ…ç»ªï¼ˆä½¿ç”¨ä¸“ä¸šsentimentè¯å…¸ï¼‰
        å¢å¼ºï¼šæ”¯æŒè½¬æŠ˜å¥å¼å’Œç§¯æè¡Œä¸ºè¯†åˆ«
        """
        # 1. æ£€æµ‹è½¬æŠ˜å¥å¼å’Œç§¯æè¡Œä¸ºï¼ˆä¼˜å…ˆçº§æœ€é«˜ï¼‰
        has_turnaround = cls._detect_turnaround_keywords(text)
        if has_turnaround:
            # æ£€æµ‹ç§¯æè¡Œä¸ºå…³é”®è¯
            positive_actions = [
                'å…‹æœ', 'åšæŒ', 'åŠªåŠ›', 'é¢å¯¹', 'æˆ˜èƒœ', 'åº”å¯¹', 'æŒ‘æˆ˜', 
                'ç»§ç»­', 'å‰è¿›', 'å¥‹æ–—', 'æ‹¼æ', 'è§£å†³', 'çªç ´', 'è¿›å–',
                'å‹‡æ•¢', 'åšå¼º', 'åšéŸ§', 'ä¸å±ˆ', 'ä¸æŒ '
            ]
            text_lower = text.lower()
            has_positive_action = any(action in text_lower for action in positive_actions)
            
            if has_positive_action:
                # è½¬æŠ˜åæ˜¯ç§¯æè¡Œä¸ºï¼Œè¯†åˆ«ä¸º"æœŸå¾…"
                current_app.logger.debug(
                    f"å…³é”®è¯åŒ¹é…ï¼šæ£€æµ‹åˆ°è½¬æŠ˜å¥å¼å’Œç§¯æè¡Œä¸ºï¼Œè¿”å›'æœŸå¾…': {text[:50]}..."
                )
                return 'æœŸå¾…'
        
        # 2. æ£€æµ‹å¼ºçƒˆæ„¤æ€’è¯æ±‡ï¼ˆä¼˜å…ˆçº§è¾ƒé«˜ï¼‰
        anger_keywords = ['æ¼ç«', 'æ„¤æ€’', 'ç”Ÿæ°”', 'æ€’ç«', 'æ°”æ„¤', 'æš´èº', 'å‘ç«', 'ä¸æ»¡', 'ç«å¤§']
        text_lower_check = text.lower()
        if any(keyword in text_lower_check for keyword in anger_keywords):
            current_app.logger.debug(
                f"å…³é”®è¯åŒ¹é…ï¼šæ£€æµ‹åˆ°å¼ºçƒˆæ„¤æ€’è¯æ±‡ï¼Œè¿”å›'æ„¤æ€’': {text[:50]}..."
            )
            return 'æ„¤æ€’'
        
        # 3. ä½¿ç”¨ä¸“ä¸šè¯å…¸
        try:
            lexicon_result = SentimentLexicon.analyze_with_lexicon(text)
            if lexicon_result and lexicon_result['emotion_scores']:
                # è¿”å›å¾—åˆ†æœ€é«˜çš„æƒ…ç»ª
                top_emotion = max(
                    lexicon_result['emotion_scores'], 
                    key=lexicon_result['emotion_scores'].get
                )
                return top_emotion
        except Exception as e:
            current_app.logger.warning(f"ä¸“ä¸šè¯å…¸åŒ¹é…å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤å…³é”®è¯: {str(e)}")
        
        # 4. é™çº§æ–¹æ¡ˆï¼šä½¿ç”¨åŸºç¡€å…³é”®è¯ï¼ˆå¦‚æœä¸“ä¸šè¯å…¸å¤±è´¥ï¼‰
        emotion_keywords = {
            'å¼€å¿ƒ': ['å¼€å¿ƒ', 'å¿«ä¹', 'é«˜å…´', 'æ„‰å¿«', 'æ¬¢ä¹', 'å–œæ‚¦', 'å…´å¥‹', 'å¼€å¿ƒåœ°', 'å¿«ä¹åœ°'],
            'éš¾è¿‡': ['éš¾è¿‡', 'æ‚²ä¼¤', 'ä¼¤å¿ƒ', 'ç—›è‹¦', 'å¤±è½', 'æ²®ä¸§', 'å­¤ç‹¬', 'æƒ³å“­', 'çœ¼æ³ª'],
            'ç„¦è™‘': ['ç„¦è™‘', 'æ‹…å¿ƒ', 'å¿§è™‘', 'ä¸å®‰', 'ç´§å¼ ', 'å‹åŠ›', 'çƒ¦æ¼', 'æ€¥èº', 'ææ…Œ'],
            'æ„¤æ€’': ['æ„¤æ€’', 'ç”Ÿæ°”', 'æ€’ç«', 'ä¸æ»¡', 'æ°”æ„¤', 'æš´èº', 'å‘ç«', 'æ¼ç«'],
            'å¹³é™': ['å¹³é™', 'å®‰é™', 'å®é™', 'æ·¡å®š', 'ä»å®¹', 'å¹³å’Œ', 'æ”¾æ¾', 'èˆ’å¿ƒ'],
            'ç–²æƒ«': ['ç–²æƒ«', 'ç´¯', 'ç–²å€¦', 'åŠ³ç´¯', 'ä¹åŠ›', 'å›°å€¦', 'ç­‹ç–²åŠ›å°½', 'å¾ˆç´¯'],
            'æ„ŸåŠ¨': ['æ„ŸåŠ¨', 'æ„Ÿæ¿€', 'æ„Ÿæ©', 'æ¸©æš–', 'æš–å¿ƒ', 'è§¦åŠ¨', 'åŠ¨å®¹', 'æ³ªç›®'],
            'å…´å¥‹': ['å…´å¥‹', 'æ¿€åŠ¨', 'æŒ¯å¥‹', 'çƒ­æƒ…', 'å……æ»¡', 'æ´»åŠ›', 'æ¿€æ˜‚', 'çƒ­è¡€'],
            'æœŸå¾…': ['æœŸå¾…', 'æœŸæœ›', 'ç›¼æœ›', 'å¸Œæœ›', 'ç­‰å¾…', 'æ†§æ†¬', 'å‘å¾€', 'æœŸç›¼'],
            'å­¤ç‹¬': ['å­¤ç‹¬', 'å¯‚å¯', 'å­¤å•', 'ç‹¬è‡ª', 'ä¸€ä¸ªäºº', 'å­¤ç«‹', 'æ— äºº', 'å¯‚å¯åœ°']
        }
        
        text_lower = text.lower()
        emotion_scores = {}
        
        for emotion_name, keywords in emotion_keywords.items():
            score = sum(1 for keyword in keywords if keyword in text_lower)
            if score > 0:
                emotion_scores[emotion_name] = score
        
        if not emotion_scores:
            return 'å¹³é™'  # é»˜è®¤è¿”å›å¹³é™
        
        # è¿”å›å¾—åˆ†æœ€é«˜çš„æƒ…ç»ª
        return max(emotion_scores, key=emotion_scores.get)
    
    @classmethod
    def _calculate_keyword_confidence(cls, text, emotion_name):
        """
        è®¡ç®—å…³é”®è¯åŒ¹é…çš„ç½®ä¿¡åº¦ï¼ˆä½¿ç”¨ä¸“ä¸šsentimentè¯å…¸ï¼‰
        
        Args:
            text: æ–‡æœ¬å†…å®¹
            emotion_name: åŒ¹é…åˆ°çš„æƒ…ç»ªåç§°
            
        Returns:
            float: ç½®ä¿¡åº¦ï¼ˆ0.0 ~ 1.0ï¼‰
        """
        if not emotion_name:
            return 0.0
        
        # ä¼˜å…ˆä½¿ç”¨ä¸“ä¸šè¯å…¸è®¡ç®—ç½®ä¿¡åº¦
        try:
            enhance_result = SentimentLexicon.enhance_keyword_matching(text, emotion_name)
            if enhance_result and enhance_result['matched']:
                # ä½¿ç”¨ä¸“ä¸šè¯å…¸çš„ç½®ä¿¡åº¦ï¼Œç»“åˆå¼ºåº¦åŠ æƒ
                confidence = enhance_result['confidence']
                intensity = enhance_result.get('intensity', 0.5)
                # å¼ºåº¦åŠ æƒï¼šå¼ºåº¦è¶Šé«˜ï¼Œç½®ä¿¡åº¦è¶Šé«˜
                final_confidence = confidence * (0.5 + intensity * 0.5)
                return min(final_confidence, 1.0)
        except Exception as e:
            current_app.logger.warning(f"ä¸“ä¸šè¯å…¸ç½®ä¿¡åº¦è®¡ç®—å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤æ–¹æ³•: {str(e)}")
        
        # é™çº§æ–¹æ¡ˆï¼šä½¿ç”¨åŸºç¡€å…³é”®è¯
        emotion_keywords = {
            'å¼€å¿ƒ': ['å¼€å¿ƒ', 'å¿«ä¹', 'é«˜å…´', 'æ„‰å¿«', 'æ¬¢ä¹', 'å–œæ‚¦', 'å…´å¥‹', 'å¼€å¿ƒåœ°', 'å¿«ä¹åœ°'],
            'éš¾è¿‡': ['éš¾è¿‡', 'æ‚²ä¼¤', 'ä¼¤å¿ƒ', 'ç—›è‹¦', 'å¤±è½', 'æ²®ä¸§', 'å­¤ç‹¬', 'æƒ³å“­', 'çœ¼æ³ª'],
            'ç„¦è™‘': ['ç„¦è™‘', 'æ‹…å¿ƒ', 'å¿§è™‘', 'ä¸å®‰', 'ç´§å¼ ', 'å‹åŠ›', 'çƒ¦æ¼', 'æ€¥èº', 'ææ…Œ'],
            'æ„¤æ€’': ['æ„¤æ€’', 'ç”Ÿæ°”', 'æ€’ç«', 'ä¸æ»¡', 'æ°”æ„¤', 'æš´èº', 'å‘ç«', 'æ¼ç«'],
            'å¹³é™': ['å¹³é™', 'å®‰é™', 'å®é™', 'æ·¡å®š', 'ä»å®¹', 'å¹³å’Œ', 'æ”¾æ¾', 'èˆ’å¿ƒ'],
            'ç–²æƒ«': ['ç–²æƒ«', 'ç´¯', 'ç–²å€¦', 'åŠ³ç´¯', 'ä¹åŠ›', 'å›°å€¦', 'ç­‹ç–²åŠ›å°½', 'å¾ˆç´¯'],
            'æ„ŸåŠ¨': ['æ„ŸåŠ¨', 'æ„Ÿæ¿€', 'æ„Ÿæ©', 'æ¸©æš–', 'æš–å¿ƒ', 'è§¦åŠ¨', 'åŠ¨å®¹', 'æ³ªç›®'],
            'å…´å¥‹': ['å…´å¥‹', 'æ¿€åŠ¨', 'æŒ¯å¥‹', 'çƒ­æƒ…', 'å……æ»¡', 'æ´»åŠ›', 'æ¿€æ˜‚', 'çƒ­è¡€'],
            'æœŸå¾…': ['æœŸå¾…', 'æœŸæœ›', 'ç›¼æœ›', 'å¸Œæœ›', 'ç­‰å¾…', 'æ†§æ†¬', 'å‘å¾€', 'æœŸç›¼'],
            'å­¤ç‹¬': ['å­¤ç‹¬', 'å¯‚å¯', 'å­¤å•', 'ç‹¬è‡ª', 'ä¸€ä¸ªäºº', 'å­¤ç«‹', 'æ— äºº', 'å¯‚å¯åœ°']
        }
        
        keywords = emotion_keywords.get(emotion_name, [])
        if not keywords:
            return 0.5
        
        text_lower = text.lower()
        matches = sum(1 for keyword in keywords if keyword in text_lower)
        max_possible = len(keywords)
        
        # ç½®ä¿¡åº¦ = åŒ¹é…æ•° / å¯èƒ½çš„å…³é”®è¯æ•°ï¼Œä½†æœ‰ä¸Šé™
        confidence = min(matches / max_possible, 1.0)
        
        # å¦‚æœåŒ¹é…å¤šä¸ªå…³é”®è¯ï¼Œæé«˜ç½®ä¿¡åº¦
        if matches >= 2:
            confidence = min(confidence + 0.2, 1.0)
        
        return max(confidence, 0.3)  # æœ€ä½ç½®ä¿¡åº¦0.3

    @classmethod
    def _get_fallback_message(cls, emotion_name):
        """è·å–é¢„è®¾å¥å­ï¼ˆé™çº§æ–¹æ¡ˆï¼‰"""
        import random
        
        messages = cls.FALLBACK_MESSAGES.get(emotion_name, cls.FALLBACK_MESSAGES['default'])
        message = random.choice(messages)
        
        return {
            'content': message,
            'model': 'fallback',
            'success': True
        }

    @classmethod
    def extract_keywords(cls, text, max_keywords=5):
        """
        æå–å…³é”®è¯ï¼ˆç®€å•å®ç°ï¼‰
        å®é™…é¡¹ç›®ä¸­å¯ä»¥ä½¿ç”¨jiebaç­‰åˆ†è¯å·¥å…·
        """
        # ç®€å•çš„å…³é”®è¯æå–
        # å®é™…ä½¿ç”¨æ—¶å»ºè®®ä½¿ç”¨æ›´ä¸“ä¸šçš„NLPå·¥å…·
        import re
        
        # ç§»é™¤æ ‡ç‚¹ç¬¦å·
        text = re.sub(r'[^\w\s]', '', text)
        
        # ç®€å•åˆ†è¯ï¼ˆæŒ‰ç©ºæ ¼å’Œé•¿åº¦ï¼‰
        words = text.split()
        
        # è¿‡æ»¤çŸ­è¯
        keywords = [w for w in words if len(w) >= 2]
        
        return keywords[:max_keywords]
    
    @classmethod
    def get_task_template(cls, task_name):
        """
        è·å–ä»»åŠ¡æ¨¡æ¿ï¼ˆå‚è€ƒcntextçš„è®¾è®¡ï¼‰
        
        Args:
            task_name: ä»»åŠ¡æ¨¡æ¿åç§°
            
        Returns:
            dict: ä»»åŠ¡æ¨¡æ¿ï¼ŒåŒ…å«promptå’Œoutput_format
        """
        return cls.EMOTION_TASK_TEMPLATES.get(task_name)
    
    @classmethod
    def analyze_emotion_enhanced(cls, text):
        """
        å¢å¼ºç‰ˆæƒ…ç»ªåˆ†æï¼ˆç»“åˆä¸“ä¸šsentimentè¯å…¸å’ŒDeepSeekï¼‰
        è¿”å›ç»“æ„åŒ–ç»“æœï¼š{label, score, confidence, intensity}
        
        Args:
            text: å¾…åˆ†æçš„æ–‡æœ¬å†…å®¹
            
        Returns:
            dict: {
                'label': str,        # æƒ…ç»ªæ ‡ç­¾åç§°
                'score': float,      # æƒ…ç»ªåˆ†å€¼ï¼ˆ-1.0 ~ 1.0ï¼Œè´Ÿæ•°ä¸ºè´Ÿé¢ï¼‰
                'confidence': float, # ç½®ä¿¡åº¦ï¼ˆ0.0 ~ 1.0ï¼‰
                'intensity': float,  # å¼ºåº¦ï¼ˆ0.0 ~ 1.0ï¼‰
                'method': str        # åˆ†ææ–¹æ³•ï¼š'hybrid'/'llm'/'lexicon'/'keyword'
            } æˆ– None
        """
        if not text or len(text.strip()) < 3:
            return None
        
        # ç¬¬ä¸€æ­¥ï¼šä½¿ç”¨ä¸“ä¸šsentimentè¯å…¸è¿›è¡Œé¢„åˆ†æ
        lexicon_result = None
        try:
            lexicon_result = SentimentLexicon.analyze_with_lexicon(text)
        except Exception as e:
            current_app.logger.warning(f"ä¸“ä¸šè¯å…¸é¢„åˆ†æå¤±è´¥: {str(e)}")
        
        # å¦‚æœä¸“ä¸šè¯å…¸ç½®ä¿¡åº¦å¾ˆé«˜ï¼Œä¼˜å…ˆä½¿ç”¨è¯å…¸ç»“æœ
        if lexicon_result and lexicon_result.get('confidence', 0) >= 0.85:
            top_emotion = max(
                lexicon_result['emotion_scores'], 
                key=lexicon_result['emotion_scores'].get
            ) if lexicon_result['emotion_scores'] else None
            
            if top_emotion:
                current_app.logger.debug(
                    f"ä¸“ä¸šè¯å…¸é«˜ç½®ä¿¡åº¦ç»“æœ: {top_emotion}, "
                    f"ç½®ä¿¡åº¦: {lexicon_result['confidence']:.2f}"
                )
                return {
                    'label': top_emotion,
                    'score': cls._calculate_emotion_score(top_emotion),
                    'confidence': lexicon_result['confidence'],
                    'intensity': lexicon_result['intensity'],
                    'method': 'lexicon_high_confidence'
                }
        
        api_key = os.getenv('DEEPSEEK_API_KEY')
        if not api_key:
            # æ²¡æœ‰API Keyï¼Œä½¿ç”¨ä¸“ä¸šè¯å…¸æˆ–å…³é”®è¯åŒ¹é…
            if lexicon_result and lexicon_result['emotion_scores']:
                top_emotion = max(
                    lexicon_result['emotion_scores'], 
                    key=lexicon_result['emotion_scores'].get
                )
                return {
                    'label': top_emotion,
                    'score': cls._calculate_emotion_score(top_emotion),
                    'confidence': lexicon_result.get('confidence', 0.6),
                    'intensity': lexicon_result.get('intensity', 0.5),
                    'method': 'lexicon'
                }
            
            # é™çº§åˆ°ç®€å•å…³é”®è¯åŒ¹é…
            label = cls._match_emotion_by_keywords(text)
            confidence = cls._calculate_keyword_confidence(text, label)
            return {
                'label': label,
                'score': cls._calculate_emotion_score(label),
                'confidence': confidence,
                'intensity': 0.5,
                'method': 'keyword'
            }
        
        try:
            from app_2.model.emotion_label import EmotionLabel
            system_labels = EmotionLabel.get_system_labels()
            emotion_names = [label.name for label in system_labels]
            emotion_list = 'ã€'.join(emotion_names)
            
            # æ£€æµ‹ç‰¹æ®Šæƒ…å†µ
            has_turnaround = cls._detect_turnaround_keywords(text)
            has_mixed_emotion = cls._detect_mixed_emotion_keywords(text)
            modal_info = cls._detect_modal_particles(text)
            
            # å¦‚æœæ£€æµ‹åˆ°æ··åˆæƒ…ç»ªï¼Œç›´æ¥è¿”å›å¾…å®š
            if has_mixed_emotion:
                return {
                    'label': 'å¾…å®š',
                    'score': 0.0,
                    'confidence': 0.9,
                    'intensity': 0.5,
                    'method': 'mixed_emotion_detection'
                }
            
            # å°†ä¸“ä¸šè¯å…¸åˆ†æç»“æœèå…¥DeepSeekæç¤ºè¯
            lexicon_hint = ""
            if lexicon_result and lexicon_result['emotion_scores']:
                # è·å–è¯å…¸åˆ†æçš„å‰3ä¸ªæƒ…ç»ªåŠå…¶å¾—åˆ†
                sorted_emotions = sorted(
                    lexicon_result['emotion_scores'].items(),
                    key=lambda x: x[1],
                    reverse=True
                )[:3]
                
                lexicon_hint = "\nğŸ’¡ ä¸“ä¸šè¯å…¸åˆ†ææç¤ºï¼š"
                lexicon_hint += f"\n   æƒ…ç»ªå€¾å‘: {lexicon_result.get('valence', 'neutral')}"
                lexicon_hint += f"\n   æƒ…ç»ªå¼ºåº¦: {lexicon_result.get('intensity', 0.5):.2f}"
                if sorted_emotions:
                    emotion_str = ', '.join([f"{name}({score:.2f})" for name, score in sorted_emotions])
                    lexicon_hint += f"\n   å€™é€‰æƒ…ç»ªï¼ˆæŒ‰å¾—åˆ†æ’åºï¼‰: {emotion_str}"
                    lexicon_hint += f"\n   å»ºè®®é‡ç‚¹è€ƒè™‘ä»¥ä¸Šå€™é€‰æƒ…ç»ªï¼Œä½†éœ€ç»“åˆä¸Šä¸‹æ–‡ç»¼åˆåˆ†æã€‚"
            
            # æ„å»ºç»“æ„åŒ–è¾“å‡ºçš„æç¤ºè¯
            prompt_parts = [
                f"åˆ†ææ–‡æœ¬çš„æƒ…ç»ªçŠ¶æ€ï¼Œè¿”å›ç»“æ„åŒ–ç»“æœã€‚",
                f"\nå¯é€‰çš„æƒ…ç»ªæ ‡ç­¾ï¼š{emotion_list}",
            ]
            
            # æ·»åŠ ä¸“ä¸šè¯å…¸åˆ†ææç¤ºï¼ˆå¦‚æœå¯ç”¨ï¼‰
            if lexicon_hint:
                prompt_parts.append(lexicon_hint)
            
            prompt_parts.extend([
                f"\nè¦æ±‚ï¼š",
                f"1. è¯†åˆ«æ–‡æœ¬çš„ä¸»è¦æƒ…ç»ªç±»å‹ï¼ˆlabelï¼‰",
                f"2. è®¡ç®—æƒ…ç»ªåˆ†å€¼ï¼ˆscoreï¼‰ï¼š",
                f"   - æ­£é¢æƒ…ç»ªï¼ˆå¼€å¿ƒã€å…´å¥‹ã€æœŸå¾…ã€æ„ŸåŠ¨ã€å¹³é™ï¼‰ï¼š0.0 ~ 1.0",
                f"   - è´Ÿé¢æƒ…ç»ªï¼ˆéš¾è¿‡ã€ç„¦è™‘ã€æ„¤æ€’ã€ç–²æƒ«ã€å­¤ç‹¬ï¼‰ï¼š-1.0 ~ 0.0",
                f"3. è¯„ä¼°ç½®ä¿¡åº¦ï¼ˆconfidenceï¼‰ï¼š0.0 ~ 1.0ï¼Œè¡¨ç¤ºè¯†åˆ«çš„æŠŠæ¡ç¨‹åº¦",
                f"4. è¯„ä¼°å¼ºåº¦ï¼ˆintensityï¼‰ï¼š0.0 ~ 1.0ï¼Œè¡¨ç¤ºæƒ…ç»ªçš„å¼ºçƒˆç¨‹åº¦",
            ])
            
            # æ·»åŠ ç‰¹æ®Šæƒ…å†µæç¤º
            if has_turnaround:
                prompt_parts.append("\nâš ï¸ æ³¨æ„ï¼šæ£€æµ‹åˆ°è½¬æŠ˜å¥å¼ï¼Œè¯·ç‰¹åˆ«æ³¨æ„è½¬æŠ˜åçš„å†…å®¹è¡¨è¾¾çœŸå®æƒ…ç»ªã€‚")
            if modal_info['has_particles']:
                particles_str = 'ã€'.join(set(modal_info['particles'])) if modal_info['particles'] else ''
                intensity_str = 'ã€'.join(set(modal_info['intensity_words'])) if modal_info['intensity_words'] else ''
                if particles_str or intensity_str:
                    prompt_parts.append(f"\nğŸ’¡ æç¤ºï¼šæ£€æµ‹åˆ°è¯­æ°”è¯å’Œå¼ºåº¦è¯ï¼Œè¯·ç»“åˆå®ƒä»¬åˆ¤æ–­æƒ…ç»ªå¼ºåº¦ã€‚")
            
            prompt_parts.append(f"\næ–‡æœ¬å†…å®¹ï¼š{text[:800]}")
            prompt_parts.append(f"\nè¯·ä»¥JSONæ ¼å¼è¿”å›ç»“æœï¼Œæ ¼å¼ï¼š{{\"label\": \"æƒ…ç»ªæ ‡ç­¾\", \"score\": 0.5, \"confidence\": 0.8, \"intensity\": 0.7}}")
            
            prompt = ''.join(prompt_parts)
            
            response = requests.post(
                'https://api.deepseek.com/v1/chat/completions',
                headers={
                    'Authorization': f'Bearer {api_key}',
                    'Content-Type': 'application/json'
                },
                json={
                    'model': 'deepseek-chat',
                    'messages': [
                        {'role': 'system', 'content': cls._build_system_message()},
                        {'role': 'user', 'content': prompt}
                    ],
                    'max_tokens': 150,  # å¢åŠ tokenæ•°ä»¥å®¹çº³JSON
                    'temperature': 0.1,
                    'top_p': 0.9,
                    'response_format': {'type': 'json_object'}  # è¦æ±‚è¿”å›JSON
                },
                timeout=20
            )
            
            if response.status_code == 200:
                data = response.json()
                result_str = data['choices'][0]['message']['content'].strip()
                
                # è§£æJSONç»“æœ
                try:
                    result = json.loads(result_str)
                    
                    # éªŒè¯ç»“æœæ ¼å¼
                    if 'label' in result:
                        label = cls._parse_emotion_result(result['label'], emotion_names)
                        if label:
                            # ç»“åˆä¸“ä¸šè¯å…¸ç»“æœå’ŒDeepSeekç»“æœ
                            llm_confidence = float(result.get('confidence', 0.8))
                            llm_intensity = float(result.get('intensity', 0.5))
                            llm_score = float(result.get('score', 0.0))
                            
                            # å¦‚æœä¸“ä¸šè¯å…¸ä¹Ÿè¯†åˆ«å‡ºäº†ç›¸åŒæˆ–ç›¸ä¼¼çš„æƒ…ç»ªï¼Œæå‡ç½®ä¿¡åº¦
                            final_confidence = llm_confidence
                            final_intensity = llm_intensity
                            
                            if lexicon_result and lexicon_result['emotion_scores']:
                                lexicon_top = max(
                                    lexicon_result['emotion_scores'], 
                                    key=lexicon_result['emotion_scores'].get
                                )
                                lexicon_score = lexicon_result['emotion_scores'].get(lexicon_top, 0)
                                
                                # å¦‚æœè¯å…¸å’ŒDeepSeekç»“æœä¸€è‡´ï¼ŒåŠ æƒæå‡ç½®ä¿¡åº¦
                                if lexicon_top == label:
                                    # ä¸¤è€…ä¸€è‡´ï¼ŒåŠ æƒè®¡ç®—ï¼šDeepSeek 70% + è¯å…¸ 30%
                                    final_confidence = llm_confidence * 0.7 + lexicon_result['confidence'] * 0.3
                                    final_confidence = min(final_confidence, 0.95)  # æœ€é«˜0.95
                                    # å¼ºåº¦å–ä¸¤è€…å¹³å‡å€¼
                                    final_intensity = (llm_intensity + lexicon_result['intensity']) / 2.0
                                    method = 'hybrid'
                                    current_app.logger.debug(
                                        f"ä¸“ä¸šè¯å…¸å’ŒDeepSeekç»“æœä¸€è‡´: {label}, "
                                        f"ç»¼åˆç½®ä¿¡åº¦: {final_confidence:.2f}"
                                    )
                                elif lexicon_score > 2.0:  # è¯å…¸æœ‰è¾ƒå¼ºçš„ä¿¡å·
                                    # ç»“æœä¸ä¸€è‡´ï¼Œä½†è¯å…¸æœ‰è¾ƒå¼ºä¿¡å·ï¼Œé™ä½ç½®ä¿¡åº¦
                                    final_confidence = llm_confidence * 0.8
                                    method = 'llm_with_lexicon_conflict'
                                    current_app.logger.debug(
                                        f"ä¸“ä¸šè¯å…¸å’ŒDeepSeekç»“æœä¸ä¸€è‡´: è¯å…¸={lexicon_top}, "
                                        f"DeepSeek={label}, ä½¿ç”¨DeepSeekç»“æœä½†é™ä½ç½®ä¿¡åº¦"
                                    )
                                else:
                                    method = 'llm'
                            else:
                                method = 'llm'
                            
                            return {
                                'label': label,
                                'score': llm_score,
                                'confidence': final_confidence,
                                'intensity': final_intensity,
                                'method': method
                            }
                except (json.JSONDecodeError, ValueError, KeyError) as e:
                    # JSONè§£æå¤±è´¥ï¼Œå°è¯•ä»æ–‡æœ¬ä¸­æå–
                    current_app.logger.warning(f"JSONè§£æå¤±è´¥: {result_str}, é”™è¯¯: {str(e)}")
                    # å°è¯•è§£ææ–‡æœ¬æ ¼å¼çš„ç»“æœ
                    if 'label' in result_str or any(name in result_str for name in emotion_names):
                        label = cls._parse_emotion_result(result_str, emotion_names)
                        if label:
                            return {
                                'label': label,
                                'score': cls._calculate_emotion_score(label),
                                'confidence': 0.7,
                                'intensity': 0.5,
                                'method': 'llm_text_parsed'
                            }
            
            # é™çº§å¤„ç†
            label = cls._match_emotion_by_keywords(text)
            confidence = cls._calculate_keyword_confidence(text, label)
            return {
                'label': label,
                'score': cls._calculate_emotion_score(label),
                'confidence': confidence,
                'intensity': 0.5,
                'method': 'keyword_fallback'
            }
            
        except requests.Timeout:
            current_app.logger.error(f"å¢å¼ºæƒ…ç»ªåˆ†æè¶…æ—¶: {text[:50]}...")
            label = cls._match_emotion_by_keywords(text)
            confidence = cls._calculate_keyword_confidence(text, label)
            return {
                'label': label,
                'score': cls._calculate_emotion_score(label),
                'confidence': confidence,
                'intensity': 0.5,
                'method': 'keyword_timeout'
            }
        except Exception as e:
            current_app.logger.error(f"å¢å¼ºæƒ…ç»ªåˆ†æå¤±è´¥: {str(e)}")
            label = cls._match_emotion_by_keywords(text)
            confidence = cls._calculate_keyword_confidence(text, label)
            return {
                'label': label,
                'score': cls._calculate_emotion_score(label),
                'confidence': confidence,
                'intensity': 0.5,
                'method': 'keyword_exception'
            }
    
    @classmethod
    def _calculate_emotion_score(cls, emotion_name):
        """
        æ ¹æ®æƒ…ç»ªåç§°è®¡ç®—æƒ…ç»ªåˆ†å€¼
        
        Args:
            emotion_name: æƒ…ç»ªæ ‡ç­¾åç§°
            
        Returns:
            float: æƒ…ç»ªåˆ†å€¼ï¼ˆ-1.0 ~ 1.0ï¼‰
        """
        if not emotion_name:
            return 0.0
        
        # æ­£é¢æƒ…ç»ª
        positive_emotions = ['å¼€å¿ƒ', 'å…´å¥‹', 'æœŸå¾…', 'æ„ŸåŠ¨', 'å¹³é™']
        # è´Ÿé¢æƒ…ç»ª
        negative_emotions = ['éš¾è¿‡', 'ç„¦è™‘', 'æ„¤æ€’', 'ç–²æƒ«', 'å­¤ç‹¬']
        
        if emotion_name in positive_emotions:
            # æ­£é¢æƒ…ç»ªï¼š0.3 ~ 1.0
            scores = {
                'å¼€å¿ƒ': 0.8,
                'å…´å¥‹': 0.9,
                'æœŸå¾…': 0.7,
                'æ„ŸåŠ¨': 0.8,
                'å¹³é™': 0.5
            }
            return scores.get(emotion_name, 0.6)
        elif emotion_name in negative_emotions:
            # è´Ÿé¢æƒ…ç»ªï¼š-1.0 ~ -0.3
            scores = {
                'éš¾è¿‡': -0.7,
                'ç„¦è™‘': -0.6,
                'æ„¤æ€’': -0.8,
                'ç–²æƒ«': -0.5,
                'å­¤ç‹¬': -0.6
            }
            return scores.get(emotion_name, -0.5)
        elif emotion_name == 'å¾…å®š':
            return 0.0
        else:
            return 0.0
    
    @classmethod
    def analyze_emotion_batch(cls, texts, max_concurrent=5):
        """
        æ‰¹é‡æƒ…ç»ªåˆ†æï¼ˆå‚è€ƒcntextçš„æ‰¹é‡å¤„ç†æ–¹å¼ï¼‰
        
        Args:
            texts: æ–‡æœ¬åˆ—è¡¨
            max_concurrent: æœ€å¤§å¹¶å‘æ•°
            
        Returns:
            list: æƒ…ç»ªåˆ†æç»“æœåˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ æ˜¯dictæˆ–None
        """
        import concurrent.futures
        
        results = []
        
        def analyze_single(text):
            try:
                return cls.analyze_emotion_enhanced(text)
            except Exception as e:
                current_app.logger.error(f"æ‰¹é‡åˆ†æå•ä¸ªæ–‡æœ¬å¤±è´¥: {str(e)}")
                return None
        
        # ä½¿ç”¨çº¿ç¨‹æ± è¿›è¡Œæ‰¹é‡å¤„ç†
        with concurrent.futures.ThreadPoolExecutor(max_workers=max_concurrent) as executor:
            future_to_text = {executor.submit(analyze_single, text): text for text in texts}
            
            for future in concurrent.futures.as_completed(future_to_text):
                try:
                    result = future.result()
                    results.append(result)
                except Exception as e:
                    current_app.logger.error(f"æ‰¹é‡åˆ†æå¤±è´¥: {str(e)}")
                    results.append(None)
        
        return results
    
    @classmethod
    def analyze_emotion_with_lexicon(cls, text):
        """
        ç»“åˆä¸“ä¸šsentimentè¯å…¸å’ŒDeepSeekçš„æ··åˆåˆ†æï¼ˆå‚è€ƒcntextçš„å¤šæ–¹æ³•ç»“åˆï¼‰
        
        å·¥ä½œæµç¨‹ï¼š
        1. ä¼˜å…ˆä½¿ç”¨ä¸“ä¸šsentimentè¯å…¸é¢„åˆ†æï¼ˆå¿«é€Ÿï¼‰
        2. å¦‚æœç½®ä¿¡åº¦é«˜ï¼ˆ>=0.85ï¼‰ï¼Œç›´æ¥è¿”å›è¯å…¸ç»“æœ
        3. å¦‚æœç½®ä¿¡åº¦ä¸­ç­‰ï¼ˆ0.7-0.85ï¼‰ï¼Œä½¿ç”¨DeepSeekå¢å¼ºåˆ†æï¼Œç»“åˆä¸¤è€…ç»“æœ
        4. å¦‚æœç½®ä¿¡åº¦ä½ï¼ˆ<0.7ï¼‰ï¼Œä½¿ç”¨DeepSeekå®Œæ•´åˆ†æ
        
        Args:
            text: å¾…åˆ†æçš„æ–‡æœ¬å†…å®¹
            
        Returns:
            dict: ç»“æ„åŒ–æƒ…ç»ªåˆ†æç»“æœ
        """
        # ç¬¬ä¸€æ­¥ï¼šä½¿ç”¨ä¸“ä¸šsentimentè¯å…¸é¢„åˆ†æ
        lexicon_result = None
        try:
            lexicon_result = SentimentLexicon.analyze_with_lexicon(text)
        except Exception as e:
            current_app.logger.warning(f"ä¸“ä¸šè¯å…¸åˆ†æå¤±è´¥: {str(e)}")
        
        # å¦‚æœä¸“ä¸šè¯å…¸ç½®ä¿¡åº¦å¾ˆé«˜ï¼ˆ>=0.85ï¼‰ï¼Œç›´æ¥è¿”å›
        if lexicon_result and lexicon_result.get('confidence', 0) >= 0.85:
            top_emotion = max(
                lexicon_result['emotion_scores'], 
                key=lexicon_result['emotion_scores'].get
            ) if lexicon_result['emotion_scores'] else None
            
            if top_emotion:
                current_app.logger.debug(
                    f"ä¸“ä¸šè¯å…¸é«˜ç½®ä¿¡åº¦ç»“æœ: {top_emotion}, "
                    f"ç½®ä¿¡åº¦: {lexicon_result['confidence']:.2f}"
                )
                return {
                    'label': top_emotion,
                    'score': cls._calculate_emotion_score(top_emotion),
                    'confidence': lexicon_result['confidence'],
                    'intensity': lexicon_result['intensity'],
                    'method': 'lexicon_high_confidence'
                }
        
        # ç¬¬äºŒæ­¥ï¼šä½¿ç”¨å¢å¼ºç‰ˆåˆ†æï¼ˆå†…éƒ¨å·²ç»“åˆsentimentè¯å…¸å’ŒDeepSeekï¼‰
        # analyze_emotion_enhanced æ–¹æ³•å†…éƒ¨ä¼šï¼š
        # 1. å…ˆç”¨sentimentè¯å…¸é¢„åˆ†æ
        # 2. å¦‚æœç½®ä¿¡åº¦>=0.85ï¼Œç›´æ¥è¿”å›
        # 3. å¦åˆ™è°ƒç”¨DeepSeekï¼Œå¹¶å°†è¯å…¸ç»“æœèå…¥æç¤ºè¯
        # 4. ç»“åˆä¸¤è€…çš„ç»“æœè®¡ç®—ç»¼åˆç½®ä¿¡åº¦
        enhanced_result = cls.analyze_emotion_enhanced(text)
        
        if enhanced_result:
            # å¢å¼ºç‰ˆåˆ†æå·²ç»ç»“åˆäº†sentimentè¯å…¸å’ŒDeepSeek
            # å¦‚æœæ–¹æ³•æ ‡è®°ä¸ºhybridï¼Œè¯´æ˜ä¸¤è€…ç»“æœä¸€è‡´
            method = enhanced_result.get('method', 'unknown')
            
            current_app.logger.debug(
                f"æ··åˆåˆ†æå®Œæˆ: {enhanced_result.get('label')}, "
                f"æ–¹æ³•: {method}, "
                f"ç½®ä¿¡åº¦: {enhanced_result.get('confidence', 0):.2f}"
            )
            
            return enhanced_result
        
        # é™çº§ï¼šå¦‚æœå¢å¼ºç‰ˆåˆ†æå¤±è´¥ï¼Œä½¿ç”¨åŸºç¡€å…³é”®è¯åŒ¹é…
        keyword_result = cls._match_emotion_by_keywords(text)
        keyword_confidence = cls._calculate_keyword_confidence(text, keyword_result)
        
        return {
            'label': keyword_result,
            'score': cls._calculate_emotion_score(keyword_result),
            'confidence': keyword_confidence,
            'intensity': 0.5,
            'method': 'keyword_fallback'
        }

